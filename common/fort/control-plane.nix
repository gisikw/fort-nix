# Fort Agent Module
#
# Defines fort.host.needs and fort.host.capabilities options for the unified control plane.
# See docs/control-plane-design.md for architecture details.
#
# fort.host.needs.<type>.<name>: Declares what a host needs from capability providers
# fort.host.capabilities.<name>: Declares what capabilities a host exposes
#
{ rootManifest, cluster, ... }:
{
  config,
  lib,
  pkgs,
  ...
}:
let
  domain = rootManifest.fortConfig.settings.domain;
  hostName = config.networking.hostName;

  # Read all host manifests for RBAC derivation
  hostFiles = builtins.readDir cluster.hostsDir;
  allHostManifests = builtins.mapAttrs
    (name: _: import (cluster.hostsDir + "/" + name + "/manifest.nix"))
    hostFiles;

  # Build hosts.json with peer public keys from cluster topology
  # For each host, get its device UUID and then the device's SSH public key
  getHostPubkey = hostName':
    let
      hostConfig = allHostManifests.${hostName'};
      deviceUuid = hostConfig.device;
      deviceManifestPath = cluster.devicesDir + "/${deviceUuid}/manifest.nix";
      deviceConfig = import deviceManifestPath;
    in {
      name = hostName';
      pubkey = deviceConfig.pubkey;
    };

  # Build hosts.json structure: { "hostname": { "pubkey": "ssh-ed25519 ..." }, ... }
  # Includes both hosts (from device manifests) and principals with agentKeys
  hostEntries = map (h:
    let info = getHostPubkey h;
    in { name = info.name; value = { pubkey = info.pubkey; }; }
  ) (builtins.attrNames allHostManifests);

  # Extract principals with agentKey for agent authentication
  principals = rootManifest.fortConfig.settings.principals or {};
  principalEntries = lib.mapAttrsToList (name: cfg:
    { inherit name; value = { pubkey = cfg.agentKey; }; }
  ) (lib.filterAttrs (name: cfg: cfg ? agentKey) principals);

  hostsJson = builtins.listToAttrs (hostEntries ++ principalEntries);

  fcgiSocket = "/run/fort/fcgi.sock";

  # Mandatory capability handlers (always present on all hosts)
  mandatoryHandlers = {
    # Return host status (generated by host-status aspect timer)
    status = pkgs.writeShellScript "handler-status" ''
      if [ -f /var/lib/fort/status/status.json ]; then
        ${pkgs.coreutils}/bin/cat /var/lib/fort/status/status.json
      else
        # Fallback if status.json doesn't exist yet
        uptime_secs=$(${pkgs.coreutils}/bin/cut -d' ' -f1 /proc/uptime | ${pkgs.coreutils}/bin/cut -d. -f1)
        ${pkgs.jq}/bin/jq -n \
          --arg hostname "${hostName}" \
          --argjson uptime "$uptime_secs" \
          --arg generated "$(${pkgs.coreutils}/bin/date -Iseconds)" \
          '{hostname: $hostname, status: "unknown", uptime_seconds: $uptime, generated_at: $generated}'
      fi
    '';

    # Return host manifest (apps, aspects, roles, exposedServices, capabilities)
    manifest = pkgs.writeShellScript "handler-manifest" ''
      ${pkgs.jq}/bin/jq -s '.[0] + {capabilities: .[1]}' \
        /var/lib/fort/host-manifest.json \
        /etc/fort/capabilities.json
    '';

    # Return holdings (handles this host is actively using)
    holdings = pkgs.writeShellScript "handler-holdings" ''
      if [ -f /var/lib/fort/holdings.json ]; then
        ${pkgs.coreutils}/bin/cat /var/lib/fort/holdings.json
      else
        echo '{"handles":[]}'
      fi
    '';

    # Return list of declared needs (for GC enumeration)
    needs = let
      needsList = lib.concatLists (lib.mapAttrsToList (capability:
        lib.mapAttrsToList (name: _: "${capability}/${name}")
      ) config.fort.host.needs);
      needsListJson = builtins.toJSON needsList;
    in pkgs.writeShellScript "handler-needs" ''
      echo '{"needs":${needsListJson}}'
    '';

    # Fetch journalctl output for a unit (debug capability)
    journal = pkgs.writeShellScript "handler-journal" ''
      set -euo pipefail

      input=$(${pkgs.coreutils}/bin/cat)
      unit=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.unit // empty')
      lines=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.lines // 100')
      since=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.since // empty')

      if [ -z "$unit" ]; then
        echo '{"error": "unit parameter required"}'
        exit 1
      fi

      # Build journalctl command
      args=("-u" "$unit" "-n" "$lines" "--no-pager" "-o" "short-iso")
      if [ -n "$since" ]; then
        args+=("--since" "$since")
      fi

      if output=$(${pkgs.systemd}/bin/journalctl "''${args[@]}" 2>&1); then
        ${pkgs.jq}/bin/jq -n --arg output "$output" '{"output": $output}'
      else
        ${pkgs.jq}/bin/jq -n --arg error "$output" '{"error": "journalctl failed", "details": $error}'
        exit 1
      fi
    '';

    # Restart a systemd unit (debug capability)
    # Optional delay parameter schedules restart in the future (useful for restarting nginx/fort-provider)
    restart = pkgs.writeShellScript "handler-restart" ''
      set -euo pipefail

      input=$(${pkgs.coreutils}/bin/cat)
      unit=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.unit // empty')
      delay=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.delay // 0')

      if [ -z "$unit" ]; then
        echo '{"error": "unit parameter required"}'
        exit 1
      fi

      # Basic validation: unit name should be reasonable
      if ! echo "$unit" | ${pkgs.gnugrep}/bin/grep -qE '^[a-zA-Z0-9@_.-]+$'; then
        echo '{"error": "invalid unit name"}'
        exit 1
      fi

      # Validate delay is a number
      if ! echo "$delay" | ${pkgs.gnugrep}/bin/grep -qE '^[0-9]+$'; then
        echo '{"error": "delay must be a non-negative integer (seconds)"}'
        exit 1
      fi

      if [ "$delay" -gt 0 ]; then
        # Schedule restart in the future - allows response to complete first
        if output=$(${pkgs.systemd}/bin/systemd-run --on-active="''${delay}s" \
            ${pkgs.systemd}/bin/systemctl restart "$unit" 2>&1); then
          ${pkgs.jq}/bin/jq -n --arg unit "$unit" --argjson delay "$delay" \
            '{"status": "scheduled", "unit": $unit, "delay_seconds": $delay}'
        else
          ${pkgs.jq}/bin/jq -n --arg unit "$unit" --arg error "$output" \
            '{"error": "schedule failed", "unit": $unit, "details": $error}'
          exit 1
        fi
      else
        # Immediate restart
        if output=$(${pkgs.systemd}/bin/systemctl restart "$unit" 2>&1); then
          ${pkgs.jq}/bin/jq -n --arg unit "$unit" '{"status": "restarted", "unit": $unit}'
        else
          ${pkgs.jq}/bin/jq -n --arg unit "$unit" --arg error "$output" \
            '{"error": "restart failed", "unit": $unit, "details": $error}'
          exit 1
        fi
      fi
    '';
  };

  # Mandatory capabilities config (all RPC - synchronous request-response)
  mandatoryCapabilities = {
    status = { mode = "rpc"; };
    manifest = { mode = "rpc"; };
    holdings = { mode = "rpc"; };
    needs = { mode = "rpc"; };
    # Debug capabilities - restricted to dev-sandbox principal
    journal = { mode = "rpc"; allowed = [ "dev-sandbox" ]; };
    restart = { mode = "rpc"; allowed = [ "dev-sandbox" ]; };
  };

  # Helper to derive needsGC and ttl from mode
  # RPC mode: synchronous, no GC needed
  # Async mode: asynchronous with handles, needs GC
  modeToGcConfig = mode: {
    needsGC = mode == "async";
    ttl = if mode == "async" then 86400 else 0;  # 24h default for async
  };

  # All capabilities = mandatory + user-defined
  # Mandatory capabilities use the new mode schema directly
  # User-defined capabilities are transformed to include derived needsGC/ttl
  allCapabilities = lib.mapAttrs (name: cfg:
    (modeToGcConfig cfg.mode) // {
      inherit (cfg) mode;
      cacheResponse = cfg.cacheResponse or false;
      triggers = cfg.triggers or { initialize = false; systemd = []; };
    } // lib.optionalAttrs (cfg ? allowed) { inherit (cfg) allowed; }
  ) mandatoryCapabilities // lib.mapAttrs (name: cfg:
    (modeToGcConfig cfg.mode) // {
      inherit (cfg) mode cacheResponse triggers;
    } // lib.optionalAttrs (cfg.allowed != null) { inherit (cfg) allowed; }
  ) config.fort.host.capabilities;

  # All hosts AND principals with agentKeys allowed to call mandatory endpoints
  principalNames = builtins.attrNames (lib.filterAttrs (name: cfg: cfg ? agentKey) principals);
  allHosts = builtins.attrNames allHostManifests ++ principalNames;

  # Derive RBAC from cluster topology
  # For each capability this host exposes, determine which hosts can call it
  deriveRbac = capabilities:
    lib.mapAttrs (capName: capCfg:
      if capCfg ? allowed && capCfg.allowed != null then
        # Restricted capability: only specified principals allowed
        capCfg.allowed
      else
        # Open capability: all cluster hosts and principals can call
        allHosts
    ) capabilities;

  # Parse duration string (e.g., "15m", "1h", "30s") to seconds
  parseDuration = str:
    let
      match = builtins.match "([0-9]+)([smh])" str;
      value = if match != null then lib.toInt (builtins.elemAt match 0) else 900;
      unit = if match != null then builtins.elemAt match 1 else "m";
    in
      if unit == "s" then value
      else if unit == "m" then value * 60
      else if unit == "h" then value * 3600
      else 900;  # default 15m

  # Need option type
  needOptions = {
    from = lib.mkOption {
      type = lib.types.str;
      description = "Hostname of the capability provider to request from";
      example = "drhorrible";
    };

    request = lib.mkOption {
      type = lib.types.attrsOf lib.types.anything;
      default = { };
      description = "Request payload passed to the capability handler";
      example = { service = "outline"; };
    };

    handler = lib.mkOption {
      type = lib.types.path;
      description = ''
        Script invoked when the need is fulfilled.
        Receives response payload on stdin.
        Exit 0 if credential was successfully processed.
        Handler is responsible for storage, transformation, and triggering restarts.
      '';
      example = "./handle-oidc-token.sh";
    };

    nag = lib.mkOption {
      type = lib.types.str;
      default = "15m";
      description = ''
        Duration after which to re-request if unsatisfied.
        Format: number + unit (s=seconds, m=minutes, h=hours).
      '';
      example = "1h";
    };
  };

  # Capability option type
  capabilityOptions = {
    handler = lib.mkOption {
      type = lib.types.path;
      description = "Path to handler script";
    };

    mode = lib.mkOption {
      type = lib.types.enum [ "rpc" "async" ];
      default = "async";
      description = ''
        Execution mode for this capability:
        - "rpc": Synchronous request-response. No GC, no handles.
        - "async": Asynchronous with state. Returns handles, requires GC.
      '';
      example = "rpc";
    };

    cacheResponse = lib.mkOption {
      type = lib.types.bool;
      default = false;
      description = ''
        Whether to cache/persist responses for the handler to reuse.
        Useful for capabilities that need to return the same response
        to multiple callers or across restarts.
      '';
    };

    triggers = lib.mkOption {
      type = lib.types.submodule {
        options = {
          initialize = lib.mkOption {
            type = lib.types.bool;
            default = false;
            description = "Run this capability handler on boot";
          };

          systemd = lib.mkOption {
            type = lib.types.listOf lib.types.str;
            default = [ ];
            description = "List of systemd unit names that trigger re-running the handler";
            example = [ "pocket-id.service" ];
          };
        };
      };
      default = { };
      description = "Trigger configuration for automatic handler invocation";
    };

    satisfies = lib.mkOption {
      type = lib.types.nullOr lib.types.str;
      default = null;
      description = ''
        The need type this capability satisfies. Used for documentation and
        potentially for RBAC derivation (finding hosts that declare matching needs).
        If null, defaults to the capability name itself.

        Example: capability "oidc-register" might set satisfies = "oidc" to match
        fort.host.needs.oidc.* declarations.
      '';
      example = "oidc";
    };

    description = lib.mkOption {
      type = lib.types.str;
      default = "";
      description = "Human-readable description of the capability";
    };

    allowed = lib.mkOption {
      type = lib.types.nullOr (lib.types.listOf lib.types.str);
      default = null;
      description = ''
        List of principal names allowed to call this capability.
        If null (default), all hosts and principals can call it.
        If specified, only the listed principals are allowed (not hosts).
      '';
      example = [ "dev-sandbox" ];
    };
  };

  # Generate needs.json from all fort.host.needs declarations
  #
  # Structure: fort.host.needs.<capability>.<name> = { from, request, handler, nag }
  # The first key IS the capability name - no magic transformation.
  # Example: fort.host.needs.ssl-cert.wildcard calls the "ssl-cert" capability
  needsJson = let
    flattenNeeds = needs:
      lib.concatLists (lib.mapAttrsToList (capability:
        lib.mapAttrsToList (name: cfg: {
          id = "${capability}-${name}";
          inherit capability;
          from = cfg.from;
          request = cfg.request;
          handler = toString cfg.handler;
          nag_seconds = parseDuration cfg.nag;
        })
      ) needs);
  in builtins.toJSON (flattenNeeds config.fort.host.needs);

  # RBAC for mandatory endpoints (respects allowed if specified)
  mandatoryRbac = deriveRbac mandatoryCapabilities;

  # Generate rbac.json from capabilities and topology (includes mandatory)
  rbacJson = builtins.toJSON (mandatoryRbac // deriveRbac config.fort.host.capabilities);

  # Generate capabilities.json with needsGC and ttl settings (includes mandatory)
  capabilitiesJson = builtins.toJSON allCapabilities;

  # Import the provider (FastCGI handler)
  fortProvider = import ../../pkgs/fort-provider { inherit pkgs; };

  # Import fort CLI for consumer service
  fortCli = import ../../pkgs/fort { inherit pkgs domain; };

  # Fulfill script - reads needs.json and calls providers
  # New schema: each need has { from, request, handler, nag_seconds }
  # Handler is invoked with response body on stdin
  fortFulfillScript = pkgs.writeShellScript "fort-fulfill" ''
    set -euo pipefail

    NEEDS_FILE="/etc/fort/needs.json"
    HOLDINGS_FILE="/var/lib/fort/holdings.json"
    HANDLES_DIR="/var/lib/fort/handles"
    FULFILLMENT_STATE_FILE="/var/lib/fort/fulfillment-state.json"

    log() { echo "[fort-fulfill] $*"; }

    # Exit early if no needs file
    if [ ! -f "$NEEDS_FILE" ]; then
      log "No needs.json found, nothing to fulfill"
      exit 0
    fi

    # Ensure handles directory exists
    ${pkgs.coreutils}/bin/mkdir -p "$HANDLES_DIR"

    # Load fulfillment state (or init empty)
    if [ -f "$FULFILLMENT_STATE_FILE" ]; then
      fulfillment_state=$(${pkgs.coreutils}/bin/cat "$FULFILLMENT_STATE_FILE")
    else
      fulfillment_state='{}'
    fi

    now=$(${pkgs.coreutils}/bin/date +%s)

    # Track holdings for final output
    declare -A HOLDINGS

    # Read needs.json and process each need
    needs=$(${pkgs.jq}/bin/jq -c '.[]' "$NEEDS_FILE")

    while IFS= read -r need; do
      [ -z "$need" ] && continue

      id=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.id')
      capability=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.capability')
      from=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.from')
      # Inject need ID into request so provider can identify callback target
      request=$(echo "$need" | ${pkgs.jq}/bin/jq -c --arg id "$id" '(.request // {}) + {"_fort_need_id": $id}')
      handler=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.handler')
      nag_seconds=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.nag_seconds // 900')

      handle_path="$HANDLES_DIR/$id"

      # Get current state for this need
      need_state=$(echo "$fulfillment_state" | ${pkgs.jq}/bin/jq -c --arg id "$id" '.[$id] // {satisfied: false, last_sought: 0}')
      satisfied=$(echo "$need_state" | ${pkgs.jq}/bin/jq -r '.satisfied')
      last_sought=$(echo "$need_state" | ${pkgs.jq}/bin/jq -r '.last_sought')

      # Load existing handle for holdings tracking
      if [ -f "$handle_path" ] && [ -s "$handle_path" ]; then
        handle=$(${pkgs.coreutils}/bin/cat "$handle_path")
        HOLDINGS["$id"]="$handle"
      fi

      # Check if already satisfied
      if [ "$satisfied" = "true" ]; then
        log "[$id] Already satisfied"
        continue
      fi

      # Check nag interval
      elapsed=$((now - last_sought))
      if [ "$elapsed" -lt "$nag_seconds" ]; then
        remaining=$((nag_seconds - elapsed))
        log "[$id] Within nag interval (''${remaining}s remaining)"
        continue
      fi

      # Update last_sought before requesting
      fulfillment_state=$(echo "$fulfillment_state" | ${pkgs.jq}/bin/jq -c --arg id "$id" --argjson now "$now" \
        '.[$id] = (.[$id] // {}) | .[$id].last_sought = $now | .[$id].satisfied = false')

      log "[$id] Calling $from/$capability..."

      if result=$(${fortCli}/bin/fort "$from" "$capability" "$request" 2>&1); then
        status=$(echo "$result" | ${pkgs.jq}/bin/jq -r '.status')
        handle=$(echo "$result" | ${pkgs.jq}/bin/jq -r '.handle // empty')
        body=$(echo "$result" | ${pkgs.jq}/bin/jq -c '.body')

        if [ "$status" -ge 200 ] && [ "$status" -lt 300 ]; then
          log "[$id] Success from $from (HTTP $status)"

          # Invoke handler with response body on stdin
          if echo "$body" | "$handler"; then
            log "[$id] Handler completed successfully"

            # Mark satisfied in state
            fulfillment_state=$(echo "$fulfillment_state" | ${pkgs.jq}/bin/jq -c --arg id "$id" \
              '.[$id].satisfied = true')

            # Store handle if returned
            if [ -n "$handle" ]; then
              ${pkgs.coreutils}/bin/mkdir -p "$HANDLES_DIR"
              echo "$handle" > "$handle_path"
              HOLDINGS["$id"]="$handle"
              log "[$id] Stored handle at $handle_path"
            fi
          else
            log "[$id] Handler failed, will retry after nag interval"
          fi
        else
          log "[$id] Provider $from returned HTTP $status"
        fi
      else
        log "[$id] Provider $from failed: $result"
      fi
    done <<< "$needs"

    # Write fulfillment state
    echo "$fulfillment_state" | ${pkgs.jq}/bin/jq '.' > "$FULFILLMENT_STATE_FILE"
    log "Updated fulfillment state"

    # Write holdings.json
    # Disable strict unset checking - associative arrays can be tricky with set -u
    set +u
    holdings_json='{"handles":['
    first=true
    for id in "''${!HOLDINGS[@]}"; do
      if [ "$first" = true ]; then
        first=false
      else
        holdings_json+=','
      fi
      holdings_json+="{\"id\":\"$id\",\"handle\":\"''${HOLDINGS[$id]}\"}"
    done
    holdings_json+=']}'
    holdings_count="''${#HOLDINGS[@]}"
    set -u  # Re-enable strict mode

    echo "$holdings_json" | ${pkgs.jq}/bin/jq '.' > "$HOLDINGS_FILE"
    log "Updated holdings.json with $holdings_count handle(s)"

    exit 0
  '';

  # Check if we have any needs or capabilities defined
  hasNeeds = config.fort.host.needs != { };
  hasCapabilities = config.fort.host.capabilities != { };

in
{
  options.fort.host = {
    needs = lib.mkOption {
      type = lib.types.attrsOf (lib.types.attrsOf (lib.types.submodule { options = needOptions; }));
      default = { };
      description = ''
        Declares what this host needs from capability providers.
        Structure: fort.host.needs.<capability>.<id> = { from, request, handler, nag }

        The first key is the capability to call. The second key is an arbitrary
        identifier for disambiguation - use "default" for singletons, or a
        descriptive id when you have multiple needs of the same capability.

        The handler script receives the response payload on stdin and is
        responsible for storage, transformation, and triggering any restarts.

        Examples:
          # Simple need with inline handler
          fort.host.needs.git-token.default = {
            from = "drhorrible";
            request = { access = "ro"; };
            handler = pkgs.writeShellScript "git-token-handler" '''
              ${pkgs.jq}/bin/jq -r '.token' > /var/lib/fort-git/token
            ''';
          };

          # OIDC registration with handler
          fort.host.needs.oidc.outline = {
            from = "drhorrible";
            request = { client_name = "outline"; };
            nag = "1h";
            handler = ./handlers/oidc-callback.sh;
          };
      '';
      example = {
        git-token.default = {
          from = "drhorrible";
          request = { access = "ro"; };
          handler = ./handle-git-token.sh;
        };
      };
    };

    capabilities = lib.mkOption {
      type = lib.types.attrsOf (lib.types.submodule { options = capabilityOptions; });
      default = { };
      description = ''
        Declares what capabilities this host exposes via the agent API.
        RBAC rules are derived automatically from cluster topology.

        Examples:
          # Simple RPC capability (synchronous request-response)
          fort.host.capabilities.ssl-cert = {
            handler = ./handlers/ssl-cert;
            mode = "rpc";
            description = "Return cluster SSL certificates";
          };

          # Async capability with GC (creates handles, needs garbage collection)
          fort.host.capabilities.oidc-register = {
            handler = ./handlers/oidc-register;
            mode = "async";  # Default - returns handles, needs GC
            description = "Register OIDC client in pocket-id";
          };

          # Capability with triggers (auto-run on boot and service restart)
          fort.host.capabilities.token-sync = {
            handler = ./handlers/token-sync;
            mode = "rpc";
            triggers = {
              initialize = true;
              systemd = [ "pocket-id.service" ];
            };
            description = "Sync deploy tokens to hosts";
          };
      '';
      example = {
        ssl-cert = {
          handler = ./handlers/ssl-cert;
          mode = "rpc";
          description = "Return cluster SSL certificates";
        };
      };
    };
  };

  config = lib.mkMerge [
    # Core agent infrastructure - always present on all hosts
    {
      # Generate hosts.json with peer public keys and install mandatory handlers
      system.activationScripts.fortProviderConfig = {
        deps = [ ];
        text = ''
          install -d -m0755 /etc/fort
          install -d -m0755 /etc/fort/handlers
          install -Dm0644 ${pkgs.writeText "hosts.json" (builtins.toJSON hostsJson)} /etc/fort/hosts.json

          # Install mandatory handlers
          install -Dm0755 ${mandatoryHandlers.status} /etc/fort/handlers/status
          install -Dm0755 ${mandatoryHandlers.manifest} /etc/fort/handlers/manifest
          install -Dm0755 ${mandatoryHandlers.holdings} /etc/fort/handlers/holdings
          install -Dm0755 ${mandatoryHandlers.needs} /etc/fort/handlers/needs
          install -Dm0755 ${mandatoryHandlers.journal} /etc/fort/handlers/journal
          install -Dm0755 ${mandatoryHandlers.restart} /etc/fort/handlers/restart

          # Install RBAC and capabilities config (includes mandatory endpoints)
          install -Dm0644 ${pkgs.writeText "rbac.json" rbacJson} /etc/fort/rbac.json
          install -Dm0644 ${pkgs.writeText "capabilities.json" capabilitiesJson} /etc/fort/capabilities.json
        '';
      };

      # Runtime directory for socket and persistent handles storage
      systemd.tmpfiles.rules = [
        "d /run/fort 0755 root root -"
        "d /var/lib/fort/handles 0700 root root -"
      ];

      # Socket activation for the FastCGI provider
      systemd.sockets.fort-provider = {
        description = "Fort Control Plane Provider Socket";
        wantedBy = [ "sockets.target" ];
        listenStreams = [ fcgiSocket ];
        socketConfig = {
          SocketMode = "0660";
          SocketUser = "root";
          SocketGroup = "nginx";
        };
      };

      # The actual service (activated by socket)
      systemd.services.fort-provider = {
        description = "Fort Control Plane Provider";
        requires = [ "fort-provider.socket" ];
        after = [ "fort-provider.socket" ];
        restartTriggers = [ fortProvider ];  # Restart when binary changes

        serviceConfig = {
          Type = "simple";
          ExecStart = "${fortProvider}/bin/fort-provider";
          StandardInput = "socket";
          StandardOutput = "socket";
          StandardError = "journal";
        };
      };

      # Watch for config changes and restart fort-provider
      # capabilities.json is regenerated on every activation and reflects all capability changes
      systemd.paths.fort-provider-config = {
        description = "Watch for fort-provider config changes";
        wantedBy = [ "multi-user.target" ];
        pathConfig = {
          PathModified = "/etc/fort/capabilities.json";
        };
      };

      systemd.services.fort-provider-config = {
        description = "Restart fort-provider on config change";
        serviceConfig = {
          Type = "oneshot";
          ExecStart = "${pkgs.systemd}/bin/systemctl restart fort-provider.service";
        };
      };

      # Control plane endpoint - VPN-only access for cluster-internal communication
      services.nginx.virtualHosts."${hostName}.fort.${domain}" = {
        locations."/fort/" = {
          extraConfig = ''
            if ($is_vpn = 0) {
              return 444;
            }

            fastcgi_pass unix:${fcgiSocket};
            include ${pkgs.nginx}/conf/fastcgi_params;
            fastcgi_param SCRIPT_NAME $uri;
            fastcgi_param REQUEST_METHOD $request_method;
            fastcgi_param CONTENT_TYPE $content_type;
            fastcgi_param CONTENT_LENGTH $content_length;
            fastcgi_param QUERY_STRING $query_string;

            # Auth headers for signature verification
            fastcgi_param HTTP_X_FORT_ORIGIN $http_x_fort_origin;
            fastcgi_param HTTP_X_FORT_TIMESTAMP $http_x_fort_timestamp;
            fastcgi_param HTTP_X_FORT_SIGNATURE $http_x_fort_signature;
          '';
        };
      };
    }

    # Generate needs.json and consumer services if any needs are declared
    (lib.mkIf hasNeeds {
      system.activationScripts.fortNeedsJson = {
        deps = [ "fortHostManifest" ];
        text = ''
          install -Dm0644 ${pkgs.writeText "needs.json" needsJson} /etc/fort/needs.json
        '';
      };

      # Consumer service - runs at activation to satisfy needs
      systemd.services.fort-consumer = {
        description = "Fort control plane consumer";
        after = [ "network-online.target" "fort-provider.service" ];
        wants = [ "network-online.target" ];
        wantedBy = [ "multi-user.target" ];

        serviceConfig = {
          Type = "oneshot";
          RemainAfterExit = true;
          ExecStart = fortFulfillScript;
        };

        path = [ fortCli pkgs.jq pkgs.coreutils pkgs.systemd ];
      };

      # Retry timer - periodically re-attempts unfulfilled needs
      systemd.timers.fort-consumer-retry = {
        description = "Retry unfulfilled fort consumer needs";
        wantedBy = [ "timers.target" ];
        timerConfig = {
          OnBootSec = "5m";
          OnUnitActiveSec = "5m";
        };
      };

      systemd.services.fort-consumer-retry = {
        description = "Retry unfulfilled fort consumer needs";
        serviceConfig = {
          Type = "oneshot";
          ExecStart = fortFulfillScript;
        };

        path = [ fortCli pkgs.jq pkgs.coreutils pkgs.systemd ];
      };
    })

    # Install user-defined capability handlers (if any)
    (lib.mkIf hasCapabilities {
      system.activationScripts.fortProviderHandlers = {
        deps = [ "fortProviderConfig" ];
        text = ''
          # Install user-defined handler scripts
          ${lib.concatStringsSep "\n" (lib.mapAttrsToList (name: cfg: ''
            install -Dm0755 ${cfg.handler} /etc/fort/handlers/${name}
          '') config.fort.host.capabilities)}
        '';
      };
    })

    # Generate systemd trigger units for capabilities with triggers.systemd
    # For each capability with systemd triggers:
    # 1. Create a oneshot service that runs the trigger logic
    # 2. Add OnSuccess= to each trigger unit to invoke our service
    (let
      # Filter to capabilities that have systemd triggers
      capsWithTriggers = lib.filterAttrs
        (name: cfg: cfg.triggers.systemd or [] != [])
        config.fort.host.capabilities;

      # Generate trigger services for each capability
      triggerServices = lib.mapAttrs' (capName: cfg:
        lib.nameValuePair "fort-provider-trigger-${capName}" {
          description = "Fort provider systemd trigger for ${capName}";
          serviceConfig = {
            Type = "oneshot";
            ExecStart = "${fortProvider}/bin/fort-provider --trigger ${capName}";
          };
        }
      ) capsWithTriggers;

      # Build a map of unit -> list of trigger services
      # This handles multiple capabilities that may trigger on the same unit
      unitToTriggers = lib.foldl' (acc: capName:
        let
          cfg = capsWithTriggers.${capName};
          triggerService = "fort-provider-trigger-${capName}.service";
        in lib.foldl' (acc': unit:
          let unitName = lib.removeSuffix ".service" unit;
          in acc' // {
            ${unitName} = (acc'.${unitName} or []) ++ [ triggerService ];
          }
        ) acc cfg.triggers.systemd
      ) {} (builtins.attrNames capsWithTriggers);

      # Generate OnSuccess drop-ins for trigger units
      triggerDropIns = lib.mapAttrs (unitName: triggerServices':
        { unitConfig.OnSuccess = triggerServices'; }
      ) unitToTriggers;

    in lib.mkIf (capsWithTriggers != {}) {
      systemd.services = triggerServices // triggerDropIns;
    })
  ];
}
