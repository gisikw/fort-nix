# Fort Agent Module
#
# Defines fort.host.needs and fort.host.capabilities options for the unified control plane.
# See docs/control-plane-design.md for architecture details.
#
# fort.host.needs.<type>.<name>: Declares what a host needs from capability providers
# fort.host.capabilities.<name>: Declares what capabilities a host exposes
#
{ rootManifest, cluster, ... }:
{
  config,
  lib,
  pkgs,
  ...
}:
let
  domain = rootManifest.fortConfig.settings.domain;
  hostName = config.networking.hostName;

  # Read all host manifests for RBAC derivation
  hostFiles = builtins.readDir cluster.hostsDir;
  allHostManifests = builtins.mapAttrs
    (name: _: import (cluster.hostsDir + "/" + name + "/manifest.nix"))
    hostFiles;

  # Build hosts.json with peer public keys from cluster topology
  # For each host, get its device UUID and then the device's SSH public key
  getHostPubkey = hostName':
    let
      hostConfig = allHostManifests.${hostName'};
      deviceUuid = hostConfig.device;
      deviceManifestPath = cluster.devicesDir + "/${deviceUuid}/manifest.nix";
      deviceConfig = import deviceManifestPath;
    in {
      name = hostName';
      pubkey = deviceConfig.pubkey;
    };

  # Build hosts.json structure: { "hostname": { "pubkey": "ssh-ed25519 ..." }, ... }
  # Includes both hosts (from device manifests) and principals with agentKeys
  hostEntries = map (h:
    let info = getHostPubkey h;
    in { name = info.name; value = { pubkey = info.pubkey; }; }
  ) (builtins.attrNames allHostManifests);

  # Extract principals with agentKey for agent authentication
  principals = rootManifest.fortConfig.settings.principals or {};
  principalEntries = lib.mapAttrsToList (name: cfg:
    { inherit name; value = { pubkey = cfg.agentKey; }; }
  ) (lib.filterAttrs (name: cfg: cfg ? agentKey) principals);

  hostsJson = builtins.listToAttrs (hostEntries ++ principalEntries);

  fcgiSocket = "/run/fort/fcgi.sock";

  # Mandatory capability handlers (always present on all hosts)
  mandatoryHandlers = {
    # Return host status (generated by host-status aspect timer)
    # Merges in provider state summary if present
    status = pkgs.writeShellScript "handler-status" ''
      # Get base status
      if [ -f /var/lib/fort/status/status.json ]; then
        base_status=$(${pkgs.coreutils}/bin/cat /var/lib/fort/status/status.json)
      else
        # Fallback if status.json doesn't exist yet
        uptime_secs=$(${pkgs.coreutils}/bin/cut -d' ' -f1 /proc/uptime | ${pkgs.coreutils}/bin/cut -d. -f1)
        base_status=$(${pkgs.jq}/bin/jq -n \
          --arg hostname "${hostName}" \
          --argjson uptime "$uptime_secs" \
          --arg generated "$(${pkgs.coreutils}/bin/date -Iseconds)" \
          '{hostname: $hostname, status: "unknown", uptime_seconds: $uptime, generated_at: $generated}')
      fi

      # Add provider state summary if present
      if [ -f /var/lib/fort/provider-state.json ]; then
        # Summarize: capability -> count of entries
        provider_summary=$(${pkgs.jq}/bin/jq 'to_entries | map({key: .key, value: (.value | length)}) | from_entries' \
          /var/lib/fort/provider-state.json)
        base_status=$(echo "$base_status" | ${pkgs.jq}/bin/jq --argjson ps "$provider_summary" '. + {provider_state: $ps}')
      fi

      # Add consumer state (fulfillment) if present
      if [ -f /var/lib/fort/fulfillment-state.json ]; then
        # Show need_id -> satisfied status
        consumer_summary=$(${pkgs.jq}/bin/jq 'to_entries | map({key: .key, value: .value.satisfied}) | from_entries' \
          /var/lib/fort/fulfillment-state.json)
        base_status=$(echo "$base_status" | ${pkgs.jq}/bin/jq --argjson cs "$consumer_summary" '. + {consumer_state: $cs}')
      fi

      echo "$base_status"
    '';

    # Return host manifest (apps, aspects, roles, exposedServices, capabilities)
    manifest = pkgs.writeShellScript "handler-manifest" ''
      ${pkgs.jq}/bin/jq -s '.[0] + {capabilities: .[1]}' \
        /var/lib/fort/host-manifest.json \
        /etc/fort/capabilities.json
    '';

    # Return list of declared needs (for GC enumeration)
    needs = let
      needsList = lib.concatLists (lib.mapAttrsToList (capability:
        lib.mapAttrsToList (name: _: "${capability}/${name}")
      ) config.fort.host.needs);
      needsListJson = builtins.toJSON needsList;
    in pkgs.writeShellScript "handler-needs" ''
      echo '{"needs":${needsListJson}}'
    '';

    # Fetch journalctl output for a unit (debug capability)
    journal = pkgs.writeShellScript "handler-journal" ''
      set -euo pipefail

      input=$(${pkgs.coreutils}/bin/cat)
      unit=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.unit // empty')
      lines=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.lines // 100')
      since=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.since // empty')

      if [ -z "$unit" ]; then
        echo '{"error": "unit parameter required"}'
        exit 1
      fi

      # Build journalctl command
      args=("-u" "$unit" "-n" "$lines" "--no-pager" "-o" "short-iso")
      if [ -n "$since" ]; then
        args+=("--since" "$since")
      fi

      if output=$(${pkgs.systemd}/bin/journalctl "''${args[@]}" 2>&1); then
        ${pkgs.jq}/bin/jq -n --arg output "$output" '{"output": $output}'
      else
        ${pkgs.jq}/bin/jq -n --arg error "$output" '{"error": "journalctl failed", "details": $error}'
        exit 1
      fi
    '';

    # Restart a systemd unit (debug capability)
    # Optional delay parameter schedules restart in the future (useful for restarting nginx/fort-provider)
    restart = pkgs.writeShellScript "handler-restart" ''
      set -euo pipefail

      input=$(${pkgs.coreutils}/bin/cat)
      unit=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.unit // empty')
      delay=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.delay // 0')

      if [ -z "$unit" ]; then
        echo '{"error": "unit parameter required"}'
        exit 1
      fi

      # Basic validation: unit name should be reasonable
      if ! echo "$unit" | ${pkgs.gnugrep}/bin/grep -qE '^[a-zA-Z0-9@_.-]+$'; then
        echo '{"error": "invalid unit name"}'
        exit 1
      fi

      # Validate delay is a number
      if ! echo "$delay" | ${pkgs.gnugrep}/bin/grep -qE '^[0-9]+$'; then
        echo '{"error": "delay must be a non-negative integer (seconds)"}'
        exit 1
      fi

      if [ "$delay" -gt 0 ]; then
        # Schedule restart in the future - allows response to complete first
        if output=$(${pkgs.systemd}/bin/systemd-run --on-active="''${delay}s" \
            ${pkgs.systemd}/bin/systemctl restart "$unit" 2>&1); then
          ${pkgs.jq}/bin/jq -n --arg unit "$unit" --argjson delay "$delay" \
            '{"status": "scheduled", "unit": $unit, "delay_seconds": $delay}'
        else
          ${pkgs.jq}/bin/jq -n --arg unit "$unit" --arg error "$output" \
            '{"error": "schedule failed", "unit": $unit, "details": $error}'
          exit 1
        fi
      else
        # Immediate restart
        if output=$(${pkgs.systemd}/bin/systemctl restart "$unit" 2>&1); then
          ${pkgs.jq}/bin/jq -n --arg unit "$unit" '{"status": "restarted", "unit": $unit}'
        else
          ${pkgs.jq}/bin/jq -n --arg unit "$unit" --arg error "$output" \
            '{"error": "restart failed", "unit": $unit, "details": $error}'
          exit 1
        fi
      fi
    '';

    # Force immediate retry of needs by resetting fulfillment state
    # Optional pattern parameter filters which needs to reset (substring match)
    # If pattern is empty/missing, resets ALL needs
    force-nag = pkgs.writeShellScript "handler-force-nag" ''
      set -euo pipefail

      STATE_FILE="/var/lib/fort/fulfillment-state.json"
      input=$(${pkgs.coreutils}/bin/cat)
      pattern=$(echo "$input" | ${pkgs.jq}/bin/jq -r '.pattern // empty')

      if [ ! -f "$STATE_FILE" ]; then
        ${pkgs.jq}/bin/jq -n '{"status": "no_state", "message": "No fulfillment state exists"}'
        exit 0
      fi

      # Count current entries
      before_count=$(${pkgs.jq}/bin/jq 'length' "$STATE_FILE")

      if [ -z "$pattern" ]; then
        # Reset everything - truncate to empty object
        echo '{}' > "$STATE_FILE"
        reset_count=$before_count
        reset_keys="all"
      else
        # Reset only matching keys (by substring match on key name)
        reset_keys=$(${pkgs.jq}/bin/jq -r --arg p "$pattern" \
          'keys[] | select(contains($p))' "$STATE_FILE" | tr '\n' ',' | sed 's/,$//')

        ${pkgs.jq}/bin/jq --arg p "$pattern" \
          'with_entries(select(.key | contains($p) | not))' \
          "$STATE_FILE" > "$STATE_FILE.tmp" && mv "$STATE_FILE.tmp" "$STATE_FILE"

        after_count=$(${pkgs.jq}/bin/jq 'length' "$STATE_FILE")
        reset_count=$((before_count - after_count))
      fi

      # Restart fort-consumer to trigger immediate retry
      ${pkgs.systemd}/bin/systemctl restart fort-consumer 2>/dev/null || true

      ${pkgs.jq}/bin/jq -n \
        --arg pattern "$pattern" \
        --argjson reset_count "$reset_count" \
        --arg reset_keys "$reset_keys" \
        '{status: "reset", pattern: (if $pattern == "" then "all" else $pattern end), reset_count: $reset_count, reset_keys: $reset_keys, consumer_restarted: true}'
    '';
  };

  # Mandatory capabilities config (all RPC - synchronous request-response)
  mandatoryCapabilities = {
    status = { mode = "rpc"; };
    manifest = { mode = "rpc"; };
    needs = { mode = "rpc"; };
    # Debug capabilities - restricted to dev-sandbox principal
    journal = { mode = "rpc"; allowed = [ "dev-sandbox" ]; };
    restart = { mode = "rpc"; allowed = [ "dev-sandbox" ]; };
    force-nag = { mode = "rpc"; allowed = [ "dev-sandbox" ]; };
  };

  # Helper to derive needsGC and ttl from mode
  # RPC mode: synchronous, no GC needed
  # Async mode: asynchronous with state, needs GC
  modeToGcConfig = mode: {
    needsGC = mode == "async";
    ttl = if mode == "async" then 86400 else 0;  # 24h default for async
  };

  # All capabilities = mandatory + user-defined
  # Mandatory capabilities use the new mode schema directly
  # User-defined capabilities are transformed to include derived needsGC/ttl
  allCapabilities = lib.mapAttrs (name: cfg:
    (modeToGcConfig cfg.mode) // {
      inherit (cfg) mode;
      cacheResponse = cfg.cacheResponse or false;
      triggers = cfg.triggers or { initialize = false; systemd = []; };
    } // lib.optionalAttrs (cfg ? allowed) { inherit (cfg) allowed; }
  ) mandatoryCapabilities // lib.mapAttrs (name: cfg:
    (modeToGcConfig cfg.mode) // {
      inherit (cfg) mode cacheResponse triggers;
    } // lib.optionalAttrs (cfg.allowed != null) { inherit (cfg) allowed; }
  ) config.fort.host.capabilities;

  # All hosts AND principals with agentKeys allowed to call mandatory endpoints
  principalNames = builtins.attrNames (lib.filterAttrs (name: cfg: cfg ? agentKey) principals);
  allHosts = builtins.attrNames allHostManifests ++ principalNames;

  # Derive RBAC from cluster topology
  # For each capability this host exposes, determine which hosts can call it
  deriveRbac = capabilities:
    lib.mapAttrs (capName: capCfg:
      if capCfg ? allowed && capCfg.allowed != null then
        # Restricted capability: only specified principals allowed
        capCfg.allowed
      else
        # Open capability: all cluster hosts and principals can call
        allHosts
    ) capabilities;

  # Parse duration string (e.g., "15m", "1h", "30s") to seconds
  parseDuration = str:
    let
      match = builtins.match "([0-9]+)([smh])" str;
      value = if match != null then lib.toInt (builtins.elemAt match 0) else 900;
      unit = if match != null then builtins.elemAt match 1 else "m";
    in
      if unit == "s" then value
      else if unit == "m" then value * 60
      else if unit == "h" then value * 3600
      else 900;  # default 15m

  # Need option type
  needOptions = {
    from = lib.mkOption {
      type = lib.types.str;
      description = "Hostname of the capability provider to request from";
      example = "drhorrible";
    };

    request = lib.mkOption {
      type = lib.types.attrsOf lib.types.anything;
      default = { };
      description = "Request payload passed to the capability handler";
      example = { service = "outline"; };
    };

    handler = lib.mkOption {
      type = lib.types.path;
      default = pkgs.writeShellScript "noop-handler" ''
        # Side-effect-only need - no handler action needed
        # Response payload is discarded, success is recorded
        ${pkgs.coreutils}/bin/cat > /dev/null
      '';
      description = ''
        Script invoked when the need is fulfilled.
        Receives response payload on stdin.
        Exit 0 if credential was successfully processed.
        Handler is responsible for storage, transformation, and triggering restarts.
        Defaults to a no-op handler for side-effect-only needs.
      '';
      example = "./handle-oidc-token.sh";
    };

    nag = lib.mkOption {
      type = lib.types.str;
      default = "15m";
      description = ''
        Duration after which to re-request if unsatisfied.
        Format: number + unit (s=seconds, m=minutes, h=hours).
      '';
      example = "1h";
    };
  };

  # Capability option type
  capabilityOptions = {
    handler = lib.mkOption {
      type = lib.types.path;
      description = "Path to handler script";
    };

    mode = lib.mkOption {
      type = lib.types.enum [ "rpc" "async" ];
      default = "async";
      description = ''
        Execution mode for this capability:
        - "rpc": Synchronous request-response. No state tracking, no GC.
        - "async": Tracks state by origin:need_id. Provider can GC when need is removed.
      '';
      example = "rpc";
    };

    cacheResponse = lib.mkOption {
      type = lib.types.bool;
      default = false;
      description = ''
        Whether to cache/persist responses for the handler to reuse.
        Useful for capabilities that need to return the same response
        to multiple callers or across restarts.
      '';
    };

    triggers = lib.mkOption {
      type = lib.types.submodule {
        options = {
          initialize = lib.mkOption {
            type = lib.types.bool;
            default = false;
            description = "Run this capability handler on boot";
          };

          systemd = lib.mkOption {
            type = lib.types.listOf lib.types.str;
            default = [ ];
            description = "List of systemd unit names that trigger re-running the handler";
            example = [ "pocket-id.service" ];
          };
        };
      };
      default = { };
      description = "Trigger configuration for automatic handler invocation";
    };

    satisfies = lib.mkOption {
      type = lib.types.nullOr lib.types.str;
      default = null;
      description = ''
        The need type this capability satisfies. Used for documentation and
        potentially for RBAC derivation (finding hosts that declare matching needs).
        If null, defaults to the capability name itself.

        Example: capability "oidc-register" might set satisfies = "oidc" to match
        fort.host.needs.oidc.* declarations.
      '';
      example = "oidc";
    };

    description = lib.mkOption {
      type = lib.types.str;
      default = "";
      description = "Human-readable description of the capability";
    };

    allowed = lib.mkOption {
      type = lib.types.nullOr (lib.types.listOf lib.types.str);
      default = null;
      description = ''
        List of principal names allowed to call this capability.
        If null (default), all hosts and principals can call it.
        If specified, only the listed principals are allowed (not hosts).
      '';
      example = [ "dev-sandbox" ];
    };
  };

  # Generate needs.json from all fort.host.needs declarations
  #
  # Structure: fort.host.needs.<capability>.<name> = { from, request, handler, nag }
  # The first key IS the capability name - no magic transformation.
  # Example: fort.host.needs.ssl-cert.wildcard calls the "ssl-cert" capability
  needsJson = let
    flattenNeeds = needs:
      lib.concatLists (lib.mapAttrsToList (capability:
        lib.mapAttrsToList (name: cfg: {
          id = "${capability}-${name}";
          inherit capability;
          from = cfg.from;
          request = cfg.request;
          handler = toString cfg.handler;
          nag_seconds = parseDuration cfg.nag;
        })
      ) needs);
  in builtins.toJSON (flattenNeeds config.fort.host.needs);

  # RBAC for mandatory endpoints (respects allowed if specified)
  mandatoryRbac = deriveRbac mandatoryCapabilities;

  # Generate rbac.json from capabilities and topology (includes mandatory)
  rbacJson = builtins.toJSON (mandatoryRbac // deriveRbac config.fort.host.capabilities);

  # Generate capabilities.json with needsGC and ttl settings (includes mandatory)
  capabilitiesJson = builtins.toJSON allCapabilities;

  # Import the provider (FastCGI handler)
  fortProvider = import ../../pkgs/fort-provider { inherit pkgs; };

  # Import fort CLI for consumer service
  fortCli = import ../../pkgs/fort { inherit pkgs domain; };

  # Fulfill script - reads needs.json and calls providers
  # New schema: each need has { from, request, handler, nag_seconds }
  # Handler is invoked with response body on stdin
  fortFulfillScript = pkgs.writeShellScript "fort-fulfill" ''
    set -euo pipefail

    NEEDS_FILE="/etc/fort/needs.json"
    FULFILLMENT_STATE_FILE="/var/lib/fort/fulfillment-state.json"

    log() { echo "[fort-fulfill] $*"; }

    # Exit early if no needs file
    if [ ! -f "$NEEDS_FILE" ]; then
      log "No needs.json found, nothing to fulfill"
      exit 0
    fi

    # Load fulfillment state (or init empty)
    if [ -f "$FULFILLMENT_STATE_FILE" ]; then
      fulfillment_state=$(${pkgs.coreutils}/bin/cat "$FULFILLMENT_STATE_FILE")
    else
      fulfillment_state='{}'
    fi

    now=$(${pkgs.coreutils}/bin/date +%s)

    # Read needs.json and process each need
    needs=$(${pkgs.jq}/bin/jq -c '.[]' "$NEEDS_FILE")

    while IFS= read -r need; do
      [ -z "$need" ] && continue

      id=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.id')
      capability=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.capability')
      from=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.from')
      # Inject need ID into request so provider can identify callback target
      request=$(echo "$need" | ${pkgs.jq}/bin/jq -c --arg id "$id" '(.request // {}) + {"_fort_need_id": $id}')
      handler=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.handler')
      nag_seconds=$(echo "$need" | ${pkgs.jq}/bin/jq -r '.nag_seconds // 900')

      # Get current state for this need
      need_state=$(echo "$fulfillment_state" | ${pkgs.jq}/bin/jq -c --arg id "$id" '.[$id] // {satisfied: false, last_sought: 0}')
      satisfied=$(echo "$need_state" | ${pkgs.jq}/bin/jq -r '.satisfied')
      last_sought=$(echo "$need_state" | ${pkgs.jq}/bin/jq -r '.last_sought')

      # Check if already satisfied
      if [ "$satisfied" = "true" ]; then
        log "[$id] Already satisfied"
        continue
      fi

      # Check nag interval
      elapsed=$((now - last_sought))
      if [ "$elapsed" -lt "$nag_seconds" ]; then
        remaining=$((nag_seconds - elapsed))
        log "[$id] Within nag interval (''${remaining}s remaining)"
        continue
      fi

      # Update last_sought before requesting
      fulfillment_state=$(echo "$fulfillment_state" | ${pkgs.jq}/bin/jq -c --arg id "$id" --argjson now "$now" \
        '.[$id] = (.[$id] // {}) | .[$id].last_sought = $now | .[$id].satisfied = false')

      log "[$id] Calling $from/$capability..."

      if result=$(${fortCli}/bin/fort "$from" "$capability" "$request" 2>&1); then
        status=$(echo "$result" | ${pkgs.jq}/bin/jq -r '.status')
        body=$(echo "$result" | ${pkgs.jq}/bin/jq -c '.body')

        if [ "$status" -ge 200 ] && [ "$status" -lt 300 ]; then
          log "[$id] Success from $from (HTTP $status)"

          # Invoke handler with response body on stdin
          if echo "$body" | "$handler"; then
            log "[$id] Handler completed successfully"

            # Mark satisfied in state
            fulfillment_state=$(echo "$fulfillment_state" | ${pkgs.jq}/bin/jq -c --arg id "$id" \
              '.[$id].satisfied = true')
          else
            log "[$id] Handler failed, will retry after nag interval"
          fi
        else
          log "[$id] Provider $from returned HTTP $status"
        fi
      else
        log "[$id] Provider $from failed: $result"
      fi
    done <<< "$needs"

    # Write fulfillment state
    echo "$fulfillment_state" | ${pkgs.jq}/bin/jq '.' > "$FULFILLMENT_STATE_FILE"
    log "Updated fulfillment state"

    exit 0
  '';

  # Check if we have any needs or capabilities defined
  hasNeeds = config.fort.host.needs != { };
  hasCapabilities = config.fort.host.capabilities != { };

in
{
  options.fort.host = {
    needs = lib.mkOption {
      type = lib.types.attrsOf (lib.types.attrsOf (lib.types.submodule { options = needOptions; }));
      default = { };
      description = ''
        Declares what this host needs from capability providers.
        Structure: fort.host.needs.<capability>.<id> = { from, request, handler, nag }

        The first key is the capability to call. The second key is an arbitrary
        identifier for disambiguation - use "default" for singletons, or a
        descriptive id when you have multiple needs of the same capability.

        The handler script receives the response payload on stdin and is
        responsible for storage, transformation, and triggering any restarts.

        Examples:
          # Simple need with inline handler
          fort.host.needs.git-token.default = {
            from = "drhorrible";
            request = { access = "ro"; };
            handler = pkgs.writeShellScript "git-token-handler" '''
              ${pkgs.jq}/bin/jq -r '.token' > /var/lib/fort-git/token
            ''';
          };

          # OIDC registration with handler
          fort.host.needs.oidc.outline = {
            from = "drhorrible";
            request = { client_name = "outline"; };
            nag = "1h";
            handler = ./handlers/oidc-callback.sh;
          };
      '';
      example = {
        git-token.default = {
          from = "drhorrible";
          request = { access = "ro"; };
          handler = ./handle-git-token.sh;
        };
      };
    };

    capabilities = lib.mkOption {
      type = lib.types.attrsOf (lib.types.submodule { options = capabilityOptions; });
      default = { };
      description = ''
        Declares what capabilities this host exposes via the agent API.
        RBAC rules are derived automatically from cluster topology.

        Examples:
          # Simple RPC capability (synchronous request-response)
          fort.host.capabilities.ssl-cert = {
            handler = ./handlers/ssl-cert;
            mode = "rpc";
            description = "Return cluster SSL certificates";
          };

          # Async capability with state tracking (provider can GC when need removed)
          fort.host.capabilities.oidc-register = {
            handler = ./handlers/oidc-register;
            mode = "async";  # Default - tracks state, supports GC
            description = "Register OIDC client in pocket-id";
          };

          # Capability with triggers (auto-run on boot and service restart)
          fort.host.capabilities.token-sync = {
            handler = ./handlers/token-sync;
            mode = "rpc";
            triggers = {
              initialize = true;
              systemd = [ "pocket-id.service" ];
            };
            description = "Sync deploy tokens to hosts";
          };
      '';
      example = {
        ssl-cert = {
          handler = ./handlers/ssl-cert;
          mode = "rpc";
          description = "Return cluster SSL certificates";
        };
      };
    };
  };

  config = lib.mkMerge [
    # Core agent infrastructure - always present on all hosts
    {
      # Generate hosts.json with peer public keys and install mandatory handlers
      system.activationScripts.fortProviderConfig = {
        deps = [ ];
        text = ''
          install -d -m0755 /etc/fort
          install -d -m0755 /etc/fort/handlers
          install -Dm0644 ${pkgs.writeText "hosts.json" (builtins.toJSON hostsJson)} /etc/fort/hosts.json

          # Install mandatory handlers
          install -Dm0755 ${mandatoryHandlers.status} /etc/fort/handlers/status
          install -Dm0755 ${mandatoryHandlers.manifest} /etc/fort/handlers/manifest
          install -Dm0755 ${mandatoryHandlers.needs} /etc/fort/handlers/needs
          install -Dm0755 ${mandatoryHandlers.journal} /etc/fort/handlers/journal
          install -Dm0755 ${mandatoryHandlers.restart} /etc/fort/handlers/restart
          install -Dm0755 ${mandatoryHandlers.force-nag} /etc/fort/handlers/force-nag

          # Install RBAC and capabilities config (includes mandatory endpoints)
          install -Dm0644 ${pkgs.writeText "rbac.json" rbacJson} /etc/fort/rbac.json
          install -Dm0644 ${pkgs.writeText "capabilities.json" capabilitiesJson} /etc/fort/capabilities.json
        '';
      };

      # Runtime directory for socket
      systemd.tmpfiles.rules = [
        "d /run/fort 0755 root root -"
      ];

      # Socket activation for the FastCGI provider
      systemd.sockets.fort-provider = {
        description = "Fort Control Plane Provider Socket";
        wantedBy = [ "sockets.target" ];
        listenStreams = [ fcgiSocket ];
        socketConfig = {
          SocketMode = "0660";
          SocketUser = "root";
          SocketGroup = "nginx";
        };
      };

      # The actual service (activated by socket)
      systemd.services.fort-provider = {
        description = "Fort Control Plane Provider";
        requires = [ "fort-provider.socket" ];
        after = [ "fort-provider.socket" ];
        restartTriggers = [ fortProvider ];  # Restart when binary changes

        serviceConfig = {
          Type = "simple";
          ExecStart = "${fortProvider}/bin/fort-provider";
          StandardInput = "socket";
          StandardOutput = "socket";
          StandardError = "journal";
        };
      };

      # Watch for config changes and restart fort-provider
      # capabilities.json is regenerated on every activation and reflects all capability changes
      systemd.paths.fort-provider-config = {
        description = "Watch for fort-provider config changes";
        wantedBy = [ "multi-user.target" ];
        pathConfig = {
          PathModified = "/etc/fort/capabilities.json";
        };
      };

      systemd.services.fort-provider-config = {
        description = "Restart fort-provider on config change";
        serviceConfig = {
          Type = "oneshot";
          ExecStart = "${pkgs.systemd}/bin/systemctl restart fort-provider.service";
        };
      };

      # Control plane endpoint - VPN-only access for cluster-internal communication
      services.nginx.virtualHosts."${hostName}.fort.${domain}" = {
        locations."/fort/" = {
          extraConfig = ''
            if ($is_vpn = 0) {
              return 444;
            }

            fastcgi_pass unix:${fcgiSocket};
            include ${pkgs.nginx}/conf/fastcgi_params;
            fastcgi_param SCRIPT_NAME $uri;
            fastcgi_param REQUEST_METHOD $request_method;
            fastcgi_param CONTENT_TYPE $content_type;
            fastcgi_param CONTENT_LENGTH $content_length;
            fastcgi_param QUERY_STRING $query_string;

            # Auth headers for signature verification
            fastcgi_param HTTP_X_FORT_ORIGIN $http_x_fort_origin;
            fastcgi_param HTTP_X_FORT_TIMESTAMP $http_x_fort_timestamp;
            fastcgi_param HTTP_X_FORT_SIGNATURE $http_x_fort_signature;
          '';
        };
      };
    }

    # Generate needs.json and consumer services if any needs are declared
    (lib.mkIf hasNeeds {
      system.activationScripts.fortNeedsJson = {
        deps = [ "fortHostManifest" ];
        text = ''
          install -Dm0644 ${pkgs.writeText "needs.json" needsJson} /etc/fort/needs.json
        '';
      };

      # Consumer service - runs at activation to satisfy needs
      systemd.services.fort-consumer = {
        description = "Fort control plane consumer";
        after = [ "network-online.target" "fort-provider.service" ];
        wants = [ "network-online.target" ];
        wantedBy = [ "multi-user.target" ];

        serviceConfig = {
          Type = "oneshot";
          RemainAfterExit = true;
          ExecStart = fortFulfillScript;
        };

        path = [ fortCli pkgs.jq pkgs.coreutils pkgs.systemd ];
      };

      # Retry timer - periodically re-attempts unfulfilled needs
      systemd.timers.fort-consumer-retry = {
        description = "Retry unfulfilled fort consumer needs";
        wantedBy = [ "timers.target" ];
        timerConfig = {
          OnBootSec = "5m";
          OnUnitActiveSec = "5m";
        };
      };

      systemd.services.fort-consumer-retry = {
        description = "Retry unfulfilled fort consumer needs";
        serviceConfig = {
          Type = "oneshot";
          ExecStart = fortFulfillScript;
        };

        path = [ fortCli pkgs.jq pkgs.coreutils pkgs.systemd ];
      };
    })

    # Install user-defined capability handlers (if any)
    (lib.mkIf hasCapabilities {
      system.activationScripts.fortProviderHandlers = {
        deps = [ "fortProviderConfig" ];
        text = ''
          # Install user-defined handler scripts
          ${lib.concatStringsSep "\n" (lib.mapAttrsToList (name: cfg: ''
            install -Dm0755 ${cfg.handler} /etc/fort/handlers/${name}
          '') config.fort.host.capabilities)}
        '';
      };
    })

    # Generate systemd trigger units for capabilities with triggers.systemd
    # For each capability with systemd triggers:
    # 1. Create a oneshot service that runs the trigger logic
    # 2. Add OnSuccess= to each trigger unit to invoke our service
    (let
      # Filter to capabilities that have systemd triggers
      capsWithTriggers = lib.filterAttrs
        (name: cfg: cfg.triggers.systemd or [] != [])
        config.fort.host.capabilities;

      # Generate trigger services for each capability
      triggerServices = lib.mapAttrs' (capName: cfg:
        lib.nameValuePair "fort-provider-trigger-${capName}" {
          description = "Fort provider systemd trigger for ${capName}";
          serviceConfig = {
            Type = "oneshot";
            ExecStart = "${fortProvider}/bin/fort-provider --trigger ${capName}";
          };
        }
      ) capsWithTriggers;

      # Build a map of unit -> list of trigger services
      # This handles multiple capabilities that may trigger on the same unit
      unitToTriggers = lib.foldl' (acc: capName:
        let
          cfg = capsWithTriggers.${capName};
          triggerService = "fort-provider-trigger-${capName}.service";
        in lib.foldl' (acc': unit:
          let unitName = lib.removeSuffix ".service" unit;
          in acc' // {
            ${unitName} = (acc'.${unitName} or []) ++ [ triggerService ];
          }
        ) acc cfg.triggers.systemd
      ) {} (builtins.attrNames capsWithTriggers);

      # Generate OnSuccess drop-ins for trigger units
      triggerDropIns = lib.mapAttrs (unitName: triggerServices':
        { unitConfig.OnSuccess = triggerServices'; }
      ) unitToTriggers;

    in lib.mkIf (capsWithTriggers != {}) {
      systemd.services = triggerServices // triggerDropIns;
    })

    # GC sweep timer for cleaning up orphaned provider state
    # Runs periodically to query consumers' needs and remove orphaned entries
    (let
      # Check if this host has any async capabilities (that need GC)
      hasAsyncCapabilities = builtins.any
        (cfg: cfg.mode == "async" || cfg.needsGC or false)
        (builtins.attrValues config.fort.host.capabilities);
    in lib.mkIf hasAsyncCapabilities {
      # Timer fires every hour
      systemd.timers.fort-provider-gc = {
        description = "Fort provider garbage collection timer";
        wantedBy = [ "timers.target" ];
        timerConfig = {
          OnBootSec = "30m";    # First run 30m after boot
          OnUnitActiveSec = "1h"; # Then every hour
          RandomizedDelaySec = "5m"; # Spread out across cluster
        };
      };

      # GC service - queries consumers and cleans up orphaned state
      systemd.services.fort-provider-gc = {
        description = "Fort provider garbage collection";
        after = [ "network-online.target" "fort-provider.service" ];
        wants = [ "network-online.target" ];

        serviceConfig = {
          Type = "oneshot";
          ExecStart = "${fortProvider}/bin/fort-provider --gc";
        };

        # fort CLI needed for querying consumer needs endpoints
        path = [ fortCli pkgs.jq pkgs.coreutils ];
      };
    })
  ];
}
