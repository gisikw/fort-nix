{"id":"fort-040","title":"oauth2-proxy groups claim not working with Pocket ID","description":"oauth2-proxy configured with --scope=groups and --oidc-groups-claim=groups but still returns 403 for users in the allowed group. Pocket ID supports groups scope/claim per OIDC discovery. Needs investigation.","status":"open","priority":4,"issue_type":"bug","created_at":"2025-12-21T23:56:02.129313-06:00","updated_at":"2025-12-30T07:13:52.114610257Z"}
{"id":"fort-0f8","title":"Add claude-code-ui to q host manifest","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T21:14:10.125918-06:00","updated_at":"2025-12-22T01:01:28.046688-06:00","closed_at":"2025-12-22T01:01:28.046688-06:00","close_reason":"Claude Code UI deployed and working on q host","dependencies":[{"issue_id":"fort-0f8","depends_on_id":"fort-zk9","type":"blocks","created_at":"2025-12-21T21:14:15.403159-06:00","created_by":"daemon"},{"issue_id":"fort-0f8","depends_on_id":"fort-4sb","type":"blocks","created_at":"2025-12-21T21:14:15.599336-06:00","created_by":"daemon"},{"issue_id":"fort-0f8","depends_on_id":"fort-ee2","type":"blocks","created_at":"2025-12-21T21:15:54.37237-06:00","created_by":"daemon"}]}
{"id":"fort-0pb","title":"Create skill for SSO integration guidance","description":"## Context\nCLAUDE.md documents the SSO modes table and the OIDC credential delivery contract, but implementing other modes (headers, basicauth, gatekeeper) still requires archaeology through examples.\n\nRather than bloating always-loaded context with howtos for every mode, create a skill that provides mode-specific implementation guidance.\n\n## Proposed skill: `adding-auth` or `sso-guide`\n\nWhen invoked, the skill would:\n1. Ask which SSO mode is being implemented\n2. Provide the relevant pattern, including:\n   - What the app needs to configure\n   - What fort.nix handles automatically\n   - Working example from the codebase\n   - Common gotchas\n\n## Modes to document\n- `oidc` - native OIDC (now documented in CLAUDE.md, but skill could expand)\n- `headers` - oauth2-proxy with X-Auth-* headers\n- `basicauth` - oauth2-proxy translating to Basic Auth\n- `gatekeeper` - login wall without identity passthrough\n\n## Also include (merged from fort-xeb)\n- The service-registry OIDC provisioning flow: dummy creds → service-registry provisions real OIDC clients → proxy restart with real creds\n- Troubleshooting tips (callback URLs, token scopes, etc.)\n\n## Notes\n- Could also cover the `groups` option for LDAP-based authorization\n- Part of broader skills transition - consider holistically with other skill candidates","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-28T02:23:10.244451095Z","updated_at":"2025-12-30T07:15:14.698133582Z","labels":["dx","sso"]}
{"id":"fort-0rj","title":"Support group-based OIDC client restrictions in pocket-id","description":"## Context\nPocket-id supports restricting OIDC client access to specific LDAP groups. This is cleaner than app-level enforcement (e.g., Forgejo's `--required-claim-*`) because:\n\n- Centralized policy: \"who can access what\" lives in one place\n- Apps stay simple - just \"use OIDC\", no group logic\n- Consistent enforcement across all services\n\n## Implementation\nExtend `service-registry` to configure group restrictions when creating OIDC clients in pocket-id.\n\nCould leverage the existing `sso.groups` option in `fortCluster.exposedServices`:\n```nix\nsso = {\n  mode = \"oidc\";\n  groups = [ \"admin\" ];  # Currently only used for oauth2-proxy\n};\n```\n\nThe registry.rb `create_pocketid_client` function would need to pass allowed groups in the API request.\n\n## Notes\n- Need to verify pocket-id API supports this (UI shows the option)\n- Once implemented, can remove app-level group checks (e.g., Forgejo's `--required-claim-*`)\n- Defense-in-depth: could keep app-level as fallback initially","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-28T03:27:02.216830613Z","updated_at":"2025-12-28T03:27:02.216830613Z","labels":["pocket-id","sso"]}
{"id":"fort-0xm","title":"CI/CD pipeline for deploys","description":"Set up CI/CD to handle deploys. Addresses previous pain points: deploy failure log visibility, sharing output between user and agent, auto-rollback debugging. Depends on self-hosted git.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-27T19:43:36.680223096Z","updated_at":"2025-12-30T04:36:50.899464279Z","closed_at":"2025-12-30T04:36:50.899464279Z","close_reason":"Closed","dependencies":[{"issue_id":"fort-0xm","depends_on_id":"fort-okx","type":"blocks","created_at":"2025-12-27T19:43:44.274304103Z","created_by":"daemon"}]}
{"id":"fort-12e","title":"Termix loses state on reboot (q)","description":"After q crashed and rebooted, termix lost its state.\n\n## Investigation needed\n\n1. Check where termix stores its state\n2. Verify if it's using `/var/lib/termix` or similar (which would be persisted)\n3. If it's using a non-persisted location (e.g., `/tmp`, home dir on tmpfs), fix it\n\n## Context\n\nq uses impermanence (tmpfs root with `/persist/system` for state). Services need to store persistent data in `/var/lib` or explicitly configure persistence.\n\n## Fix options\n\n- Configure termix to use `/var/lib/termix` for state\n- Or add its state directory to impermanence persistence rules","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-29T23:25:55.532266246Z","updated_at":"2025-12-30T05:40:15.049807754Z","closed_at":"2025-12-30T05:40:15.049807754Z","close_reason":"Closed"}
{"id":"fort-1w6","title":"Configure gh CLI for Forgejo","description":"The gh CLI can apparently be configured to work with Forgejo instances.\n\nThis would enable:\n- `gh run list` to check CI status\n- `gh pr` commands\n- Other gh conveniences from dev-sandbox\n\nInvestigate how to configure this and add it to dev-sandbox aspect if viable.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-29T23:32:45.355476089Z","updated_at":"2025-12-30T07:10:32.407495174Z","closed_at":"2025-12-30T07:10:32.407495174Z","close_reason":"gh CLI doesn't support non-GitHub forges. The alternative (tea CLI) also lacks workflow run monitoring - its 'actions' command only manages secrets/variables. No clean CLI solution exists for the original use case."}
{"id":"fort-244","title":"Create pkgs/claude-code-ui derivation","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T21:14:09.480545-06:00","updated_at":"2025-12-21T21:23:44.616418-06:00","closed_at":"2025-12-21T21:23:44.616418-06:00","close_reason":"Superseded by fort-xzk and fort-69s for proper npm derivations"}
{"id":"fort-2i8","title":"Improve deploy-rs failure debugging","description":"When deploy-rs fails, currently requires SSH + journalctl to diagnose. Options: capture activation logs, surface systemd failures in deploy output, or create a 'just diagnose \u003chost\u003e' helper that pulls recent failures.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T11:41:09.489375-06:00","updated_at":"2025-12-27T19:43:36.211456156Z","closed_at":"2025-12-27T19:43:36.211456156Z","close_reason":"Superseded by CI/CD approach"}
{"id":"fort-2xw","title":"Deprovision claude-code-ui from q host","description":"Remove claude-code-ui app module from q host manifest, delete the derivations and app module code. CC-UI approach abandoned in favor of direct ratched dev environment.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:31:29.319511184Z","updated_at":"2025-12-28T06:59:02.666281142Z","closed_at":"2025-12-28T06:59:02.666281142Z","close_reason":"Closed"}
{"id":"fort-49n","title":"Wire more services behind Pocket ID/LDAP auth","description":"Extend SSO coverage. Candidates: SillyTavern, qbittorrent (likely feasible). Jellyfin, Home Assistant (harder - native auth integration). Current SSO modes: none, oidc, headers, basicauth, gatekeeper. Need to verify each service's auth capabilities.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-21T11:41:08.545668-06:00","updated_at":"2025-12-21T11:41:08.545668-06:00","dependencies":[{"issue_id":"fort-49n","depends_on_id":"fort-4fm","type":"blocks","created_at":"2025-12-21T11:41:23.088026-06:00","created_by":"daemon"}]}
{"id":"fort-4fm","title":"Custom derivation for Pocket ID","description":"Pocket ID on forge (drhorrible) currently requires nixpkgs unstable. Create custom derivation following Zot pattern to pin specific version and allow stable channel on forge host.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T11:41:08.237954-06:00","updated_at":"2025-12-21T14:10:09.907207-06:00","closed_at":"2025-12-21T14:10:09.907207-06:00","close_reason":"Closed","dependencies":[{"issue_id":"fort-4fm","depends_on_id":"fort-ax1","type":"blocks","created_at":"2025-12-21T11:41:22.888708-06:00","created_by":"daemon"}]}
{"id":"fort-4ge","title":"Module refactor: express inter-service dependencies","description":"Currently host manifests must 'just know' service dependencies. Refactor to load unparameterized module definitions into a dict first, allowing modules to express dependencies on other services (e.g., zigbee2mqtt depends on mosquitto). Manifests then select from available modules.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-21T11:41:08.858223-06:00","updated_at":"2025-12-21T11:41:08.858223-06:00"}
{"id":"fort-4ih","title":"Fix claude-code derivation - binary is raw bun, not bundled app","description":"The binary downloaded from Anthropic's GCS bucket is just raw bun runtime, not Claude Code bundled into bun. Need to investigate proper installation - may need to run 'claude install' post-download or use npm package instead.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-22T00:39:34.734941-06:00","updated_at":"2025-12-27T11:43:16.392596-06:00","closed_at":"2025-12-27T11:43:16.392596-06:00","close_reason":"Fixed with npm/buildNpmPackage approach, version 2.0.76"}
{"id":"fort-4sb","title":"Add Anthropic API key secret","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T21:14:09.910321-06:00","updated_at":"2025-12-21T22:15:27.382419-06:00","closed_at":"2025-12-21T22:15:27.382419-06:00","close_reason":"Not needed - using OAuth login instead of API key"}
{"id":"fort-549","title":"Derive VPN CIDR from mesh config instead of hardcoding","description":"The nginx geo block in common/fort.nix hardcodes 100.64.0.0/10 (Tailscale's CGNAT range). This should be derived from mesh/tailscale config to avoid magic numbers that happen to align with our tailnet setup.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-30T07:38:10.952090605Z","updated_at":"2025-12-30T07:38:10.952090605Z"}
{"id":"fort-5g7","title":"Improve AGENTS.md with project context","description":"Current AGENTS.md is minimal (just bd reference). Add: architecture overview, key patterns (fortCluster.exposedServices, SSO modes, derivation pattern), common tasks, deployment workflow, debugging tips.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T11:41:09.171375-06:00","updated_at":"2025-12-21T12:10:34.249686-06:00","closed_at":"2025-12-21T12:10:34.249686-06:00","close_reason":"Closed"}
{"id":"fort-69s","title":"Create pkgs/claude-code-ui derivation for @siteboon/claude-code-ui","description":"Replace runtime npm install with proper Nix derivation using buildNpmPackage or similar","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T21:23:27.494844-06:00","updated_at":"2025-12-21T22:17:42.510421-06:00","closed_at":"2025-12-21T22:17:42.510421-06:00","close_reason":"Derivation written and evaluates cleanly - runtime verification deferred to deploy"}
{"id":"fort-89e","title":"Unified runtime control plane","description":"Replace the current fragmented credential delivery and service discovery mechanisms with a unified agent-based control plane.\n\n## Design Document\n\nSee `docs/control-plane-design.md` for full technical design.\n\n## Architecture Summary\n\n**Agent:** Generic capability-exposure mechanism. Every host runs one. CGI handlers behind nginx at `/agent/*`. Auth via SSH signatures, RBAC from cluster topology. All POST. Handle/TTL in response headers for GC.\n\n**Fulfillment:** How hosts resolve their needs at activation. `fort-fulfill.service` reads `needs.json`, calls providers, stores results. Best-effort (doesn't block deploy). Timer retries failures.\n\n**Holdings Protocol:** Distributed GC. Providers return handles, callers advertise them via `/agent/holdings`. Positive absence triggers cleanup.\n\n**Two providers:**\n- **Forge** (drhorrible): Identity \u0026 secrets - OIDC registration, SSL certs, git tokens\n- **Beacon** (raishan): Network edge - public proxy config\n\n## Nix Abstractions\n\n- `fort.needs.*` - Apps declare what they need, system generates needs.json\n- `fort.capabilities.*` - Providers declare what they expose, system generates handlers + RBAC\n- `needsGC = true` - Auto-wires handle headers and GC timer\n\n## Key Decisions\n\n- Hosts pull from providers (not push-based)\n- Deploy resilience: fulfillment is best-effort, never blocks deploy\n- CGI-style handlers (bash scripts, upgradeable to Go/Rust per-endpoint)\n- Holdings protocol for distributed GC (two-generals safe)\n\n## Related Tickets\n\n- fort-c33: Consolidate fortCluster options under fort.cluster (absorb into this epic)\n- fort-0rj: Group-based OIDC client restrictions (adjacent, not blocking)\n- fort-bkv: Typo bug in outline tmpfiles (quick fix)\n\n## Migration Path\n\n1. Add agent to all hosts (mandatory endpoints: status, manifest, holdings, release)\n2. Add forge capabilities (oidc-register, ssl-cert, git-token)\n3. Add beacon capabilities (proxy-configure)\n4. Add fort-fulfill.service\n5. Run in parallel with existing SSH-based mechanisms\n6. Validate all coordination patterns\n7. Remove SSH-based delivery (service-registry, acme-sync, token-sync)\n8. Enable GC sweeps\n\n## Audit Notes (from codebase review)\n\n- Only outline uses sso.mode=\"oidc\" directly (forgejo has custom setup)\n- 17 apps use custom subdomains (goes in request field)\n- Path consolidation needed: various /var/lib/fort-* paths → /var/lib/fort/\n- Current beacon is passive (receives nginx config via SCP) - needs real provider implementation","status":"open","priority":3,"issue_type":"epic","created_at":"2025-12-28T05:10:28.14077079Z","updated_at":"2025-12-30T21:24:38.039319153Z"}
{"id":"fort-89e.1","title":"Agent Nix module skeleton","description":"Create aspects/fort-agent/ module structure:\n- Generate /etc/fort-agent/ directory (handlers/, rbac.json, hosts.json with peer public keys)\n- Nginx location for /agent/* → FastCGI socket\n- Systemd socket activation for wrapper\n- Wire host SSH keys from cluster topology into hosts.json\n\nThis is the foundation - no actual wrapper implementation yet, just scaffolding.","acceptance_criteria":"- /etc/fort-agent/ structure exists on hosts with fort-agent enabled\n- nginx routes /agent/* to FastCGI socket\n- hosts.json contains peer public keys from cluster topology","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:00:42.251940795Z","updated_at":"2025-12-30T22:00:42.251940795Z","dependencies":[{"issue_id":"fort-89e.1","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:00:42.25300164Z","created_by":"daemon"}]}
{"id":"fort-89e.10","title":"Migrate dev-sandbox git access to control plane","description":"Switch git token distribution from timer-push to agent-pull:\n\n1. Add fort.needs.git-token to dev-sandbox aspect\n2. Store token at /var/lib/fort-git/forge-token (existing location)\n3. Verify git operations work\n4. Remove forgejo-deploy-token-sync timer from forgejo app\n\nShould be straightforward - same pattern as cert migration.","acceptance_criteria":"- dev-sandbox hosts receive git tokens via control plane\n- Git clone/push works with new token delivery\n- forgejo-deploy-token-sync removed","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:03:38.868657192Z","updated_at":"2025-12-30T22:03:38.868657192Z","dependencies":[{"issue_id":"fort-89e.10","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:03:38.879028619Z","created_by":"daemon"},{"issue_id":"fort-89e.10","depends_on_id":"fort-89e.9","type":"blocks","created_at":"2025-12-30T22:07:01.056221502Z","created_by":"daemon"},{"issue_id":"fort-89e.10","depends_on_id":"fort-89e.7","type":"blocks","created_at":"2025-12-30T22:07:01.106484983Z","created_by":"daemon"}]}
{"id":"fort-89e.11","title":"attic-token capability","description":"Handler on forge that creates/returns Attic cache tokens:\n\nRequest: { host: \"ursula\" }\nResponse: { token: \"...\" }\nHandle: yes (for GC)\n\nUses attic CLI to create token with appropriate permissions.\nReplaces current token distribution in attic bootstrap.","acceptance_criteria":"- Handler creates attic token via CLI\n- Returns handle for GC tracking\n- Token has correct cache permissions","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:03:54.859465037Z","updated_at":"2025-12-30T22:03:54.859465037Z","dependencies":[{"issue_id":"fort-89e.11","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:03:54.868383319Z","created_by":"daemon"},{"issue_id":"fort-89e.11","depends_on_id":"fort-89e.4","type":"blocks","created_at":"2025-12-30T22:07:01.158562815Z","created_by":"daemon"},{"issue_id":"fort-89e.11","depends_on_id":"fort-89e.5","type":"blocks","created_at":"2025-12-30T22:07:01.209230946Z","created_by":"daemon"}]}
{"id":"fort-89e.12","title":"Migrate attic token distribution to control plane","description":"Switch attic token distribution to agent-pull:\n\n1. Add fort.needs.attic-token to relevant hosts/aspects\n2. Store token at existing location\n3. Verify nix builds can push to cache\n4. Remove old distribution mechanism from attic app\n\nReview apps/attic/ to identify current distribution pattern.","acceptance_criteria":"- Hosts receive attic tokens via control plane\n- Nix builds successfully push to cache\n- Old distribution mechanism removed","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:04:21.39373523Z","updated_at":"2025-12-30T22:04:21.39373523Z","dependencies":[{"issue_id":"fort-89e.12","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:04:21.403778529Z","created_by":"daemon"},{"issue_id":"fort-89e.12","depends_on_id":"fort-89e.11","type":"blocks","created_at":"2025-12-30T22:07:01.255367354Z","created_by":"daemon"},{"issue_id":"fort-89e.12","depends_on_id":"fort-89e.7","type":"blocks","created_at":"2025-12-30T22:07:01.30586868Z","created_by":"daemon"}]}
{"id":"fort-89e.13","title":"oidc-register capability","description":"Handler on forge that registers OIDC clients in pocket-id:\n\nRequest: { service: \"outline\", fqdn: \"outline.example.com\" }\nResponse: { client_id: \"...\", client_secret: \"...\" }\nHandle: yes (client ID for GC)\n\nUses pocket-id API via service key.\nReplaces create_pocketid_client logic in service-registry.\n\nRBAC: all hosts (simplest) or hosts with SSO-enabled services.","acceptance_criteria":"- Handler creates OIDC client via pocket-id API\n- Returns client_id and client_secret\n- Returns handle for GC tracking","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:04:44.908884915Z","updated_at":"2025-12-30T22:04:44.908884915Z","dependencies":[{"issue_id":"fort-89e.13","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:04:44.918284702Z","created_by":"daemon"},{"issue_id":"fort-89e.13","depends_on_id":"fort-89e.4","type":"blocks","created_at":"2025-12-30T22:07:01.484507416Z","created_by":"daemon"},{"issue_id":"fort-89e.13","depends_on_id":"fort-89e.5","type":"blocks","created_at":"2025-12-30T22:07:01.534872836Z","created_by":"daemon"}]}
{"id":"fort-89e.14","title":"Migrate outline to control plane OIDC","description":"First OIDC consumer migration:\n\n1. Add fort.needs.oidc.outline to outline app\n2. Store at /var/lib/fort/oidc/outline/{client-id,client-secret}\n3. Update outline config to read from new location (or symlink)\n4. Verify outline SSO login works\n\nThis validates the OIDC flow end-to-end before migrating other services.","acceptance_criteria":"- Outline receives OIDC creds via control plane\n- SSO login works\n- No manual credential setup required","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:04:48.686666459Z","updated_at":"2025-12-30T22:04:48.686666459Z","dependencies":[{"issue_id":"fort-89e.14","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:04:48.69625279Z","created_by":"daemon"},{"issue_id":"fort-89e.14","depends_on_id":"fort-89e.13","type":"blocks","created_at":"2025-12-30T22:07:01.586365075Z","created_by":"daemon"},{"issue_id":"fort-89e.14","depends_on_id":"fort-89e.7","type":"blocks","created_at":"2025-12-30T22:07:01.638478587Z","created_by":"daemon"}]}
{"id":"fort-89e.15","title":"Holdings management and GC foundation","description":"Infrastructure for distributed GC:\n\n1. /var/lib/fort/holdings.json structure: { handles: [\"sha256:...\", ...] }\n2. Helper scripts: fort-holdings-add, fort-holdings-remove\n3. Wire holdings endpoint to return this file\n4. Release endpoint (self-release mode):\n   - Remove handles from holdings.json\n   - Notify relevant providers\n\nProvider-side GC (checking holdings, sweeping orphans) is separate ticket.","acceptance_criteria":"- holdings.json maintained correctly\n- Holdings endpoint returns current handles\n- Release endpoint removes handles and notifies providers","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:04:52.341823463Z","updated_at":"2025-12-30T22:04:52.341823463Z","dependencies":[{"issue_id":"fort-89e.15","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:04:52.351364146Z","created_by":"daemon"},{"issue_id":"fort-89e.15","depends_on_id":"fort-89e.4","type":"blocks","created_at":"2025-12-30T22:07:01.690716942Z","created_by":"daemon"}]}
{"id":"fort-89e.16","title":"proxy-configure capability","description":"Handler on beacon that configures nginx reverse proxy:\n\nRequest: { service: \"outline\", fqdn: \"outline.example.com\", upstream: \"10.0.0.5:4654\" }\nResponse: { configured: true }\nNo handle - beacon maintains its own nginx state.\n\nGenerates server block, writes to /var/lib/fort/nginx/services/\u003cservice\u003e.conf, reloads nginx.\nReplaces public_vhosts logic in service-registry.\n\n2xx = 'I have configured the proxy for this service'","acceptance_criteria":"- Handler generates valid nginx config\n- nginx reloads successfully\n- Service is accessible through beacon","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:04:56.988134132Z","updated_at":"2025-12-30T22:04:56.988134132Z","dependencies":[{"issue_id":"fort-89e.16","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:04:57.005270277Z","created_by":"daemon"},{"issue_id":"fort-89e.16","depends_on_id":"fort-89e.4","type":"blocks","created_at":"2025-12-30T22:07:01.74446846Z","created_by":"daemon"},{"issue_id":"fort-89e.16","depends_on_id":"fort-89e.5","type":"blocks","created_at":"2025-12-30T22:07:01.794416255Z","created_by":"daemon"}]}
{"id":"fort-89e.17","title":"Wire exposedServices.visibility=public to proxy needs","description":"Auto-generate fort.needs.proxy from exposedServices:\n\nWhen a service declares visibility = 'public':\n- Generate fort.needs.proxy.\u003cservice\u003e automatically\n- Provider: beacon host\n- Request: { service, fqdn, upstream }\n\nThis replaces the service-registry scan that finds public services and pushes nginx config.\n\nImplementation in common/fort.nix or related module.","acceptance_criteria":"- Public services automatically get proxy needs generated\n- No manual fort.needs.proxy declaration required\n- Proxy configuration happens via fulfillment","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:05:29.325064741Z","updated_at":"2025-12-30T22:05:29.325064741Z","dependencies":[{"issue_id":"fort-89e.17","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:05:29.334141293Z","created_by":"daemon"},{"issue_id":"fort-89e.17","depends_on_id":"fort-89e.16","type":"blocks","created_at":"2025-12-30T22:07:01.844268093Z","created_by":"daemon"},{"issue_id":"fort-89e.17","depends_on_id":"fort-89e.7","type":"blocks","created_at":"2025-12-30T22:07:01.891696903Z","created_by":"daemon"}]}
{"id":"fort-89e.18","title":"DNS update capabilities","description":"Handlers for DNS record management:\n\n1. headscale-dns (beacon): Update /var/lib/headscale/extra-records.json\n   - Request: { records: [{name, type, value}, ...] }\n   - Manages MagicDNS entries for VPN-internal resolution\n\n2. coredns-update (forge): Update /var/lib/coredns/custom.conf  \n   - Request: { records: [{ip, fqdn}, ...] }\n   - Manages LAN DNS entries\n\nThese replace the DNS update logic in service-registry.\nMay need to rethink: currently service-registry computes all records centrally.\nWith pull model, each host would declare its own records? Or forge aggregates?","design":"Open question: per-host DNS declarations vs centralized computation. \nCurrent model scans all hosts and computes full record set.\nPull model options:\nA) Each host declares its DNS records as needs (inverted - host pushes to DNS provider)\nB) DNS providers poll hosts for their desired records\nC) Hybrid - fulfillment on DNS hosts pulls manifest from each host\n\nLeaning toward (A) with 'dns-register' capability - host says 'please add this A record'.","acceptance_criteria":"- DNS records updated via control plane\n- Both headscale and coredns records managed\n- Old service-registry DNS logic removable","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:06:04.752994195Z","updated_at":"2025-12-30T22:06:04.752994195Z","dependencies":[{"issue_id":"fort-89e.18","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:06:04.762973011Z","created_by":"daemon"},{"issue_id":"fort-89e.18","depends_on_id":"fort-89e.4","type":"blocks","created_at":"2025-12-30T22:07:02.080757126Z","created_by":"daemon"},{"issue_id":"fort-89e.18","depends_on_id":"fort-89e.5","type":"blocks","created_at":"2025-12-30T22:07:02.132473693Z","created_by":"daemon"}]}
{"id":"fort-89e.19","title":"Remove service-registry aspect","description":"After all functionality migrated to control plane:\n\n1. Verify all consumers working via new system:\n   - OIDC registration ✓\n   - Proxy configuration ✓\n   - DNS updates ✓\n2. Remove aspects/service-registry/ entirely\n3. Remove registry.rb and related systemd units\n4. Clean up any references in host manifests\n\nThis is the 'flip the switch' moment for the control plane.","acceptance_criteria":"- service-registry aspect deleted\n- No regressions in OIDC, proxy, or DNS functionality\n- All coordination happens via agent calls","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:06:08.611599466Z","updated_at":"2025-12-30T22:06:08.611599466Z","dependencies":[{"issue_id":"fort-89e.19","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:06:08.62185879Z","created_by":"daemon"},{"issue_id":"fort-89e.19","depends_on_id":"fort-89e.8","type":"blocks","created_at":"2025-12-30T22:07:02.181886646Z","created_by":"daemon"},{"issue_id":"fort-89e.19","depends_on_id":"fort-89e.14","type":"blocks","created_at":"2025-12-30T22:07:02.229839078Z","created_by":"daemon"},{"issue_id":"fort-89e.19","depends_on_id":"fort-89e.17","type":"blocks","created_at":"2025-12-30T22:07:02.280299263Z","created_by":"daemon"},{"issue_id":"fort-89e.19","depends_on_id":"fort-89e.18","type":"blocks","created_at":"2025-12-30T22:07:02.331257531Z","created_by":"daemon"}]}
{"id":"fort-89e.2","title":"Go FastCGI wrapper","description":"Implement pkgs/fort-agent-wrapper/main.go (~300 lines):\n- Parse X-Fort-Origin, X-Fort-Timestamp, X-Fort-Signature headers\n- Verify SSH signature against /etc/fort-agent/hosts.json\n- Timestamp validation (reject if \u003e5min drift)\n- Check RBAC against /etc/fort-agent/rbac.json\n- Exec handler script from /etc/fort-agent/handlers/\n- Capture stdout as response body\n- Pass through X-Fort-Handle / X-Fort-TTL headers from handler\n\nSignature format: sign(method + path + timestamp + sha256(body)) using ssh-keygen -Y sign format.","acceptance_criteria":"- Wrapper authenticates requests using SSH signatures\n- Invalid signatures return 401\n- RBAC violations return 403\n- Valid requests dispatch to handler and return response","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:00:46.237689762Z","updated_at":"2025-12-30T22:00:46.237689762Z","dependencies":[{"issue_id":"fort-89e.2","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:00:46.246967447Z","created_by":"daemon"},{"issue_id":"fort-89e.2","depends_on_id":"fort-89e.1","type":"blocks","created_at":"2025-12-30T22:07:00.189152949Z","created_by":"daemon"}]}
{"id":"fort-89e.20","title":"Enable GC sweeps","description":"Provider-side garbage collection:\n\n1. Add GC timer to forge (and beacon if needed)\n2. For each capability with needsGC:\n   - Get list of issued handles from provider state\n   - For each handle, check holder's /agent/holdings\n   - If 200 + handle absent: mark eligible (after grace period)\n   - If 200 + handle present: still in use\n   - If error: assume still in use (two-generals safe)\n3. Sweep eligible handles:\n   - OIDC: delete pocket-id client\n   - Git tokens: revoke Forgejo token\n   - Attic tokens: revoke attic token\n\nGrace period: configurable, default 1 hour?","acceptance_criteria":"- GC timer runs on providers\n- Orphan credentials identified correctly\n- Credentials revoked after grace period\n- No false positives (never revoke in-use credentials)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:06:15.47832576Z","updated_at":"2025-12-30T22:06:15.47832576Z","dependencies":[{"issue_id":"fort-89e.20","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:06:15.48732162Z","created_by":"daemon"},{"issue_id":"fort-89e.20","depends_on_id":"fort-89e.15","type":"blocks","created_at":"2025-12-30T22:07:02.383836902Z","created_by":"daemon"},{"issue_id":"fort-89e.20","depends_on_id":"fort-89e.19","type":"blocks","created_at":"2025-12-30T22:07:02.437329275Z","created_by":"daemon"}]}
{"id":"fort-89e.21","title":"Large file transfer protocol","description":"Design and implement secure large file transfer over control plane.\n\nPrimary use case: Media ingestion - 'please put this 100GB file on the NAS'\n\nThe agent protocol is request/response JSON, not suitable for large transfers.\nNeed a separate protocol built on top of the agent:\n\nOptions to explore:\n1. Agent returns a ticket (nonce + port + one-time TLS cert), separate listener accepts upload\n2. Agent returns a signed URL for direct upload to destination\n3. Agent coordinates rsync/rclone with pre-shared credentials\n\nConsiderations:\n- Must be encrypted in transit\n- Must handle connection failures gracefully\n- Must not exhaust file descriptors with unclaimed transfers\n- Timeout/cleanup for abandoned transfers\n\nThis is a design + implementation ticket - flesh out the approach before building.","design":"Deferred until core control plane is working.\nStart with design doc exploring the options above.\nMay want to prototype with a simple use case before full implementation.","acceptance_criteria":"- Design document with chosen approach\n- Working implementation for file upload to NAS\n- Handles failures gracefully (timeouts, cleanup)\n- No resource leaks","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-30T22:06:45.735240703Z","updated_at":"2025-12-30T22:06:45.735240703Z","dependencies":[{"issue_id":"fort-89e.21","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:06:45.744503456Z","created_by":"daemon"},{"issue_id":"fort-89e.21","depends_on_id":"fort-89e.19","type":"blocks","created_at":"2025-12-30T22:07:02.48988502Z","created_by":"daemon"}]}
{"id":"fort-89e.3","title":"fort-agent-call client","description":"Bash script in pkgs/fort-agent-call/:\n- Sign request body with host's SSH key (ssh-keygen -Y sign)\n- Build canonical string: METHOD\\nPATH\\nTIMESTAMP\\nSHA256(body)\n- POST via curl with X-Fort-Origin, X-Fort-Timestamp, X-Fort-Signature headers\n- Parse X-Fort-Handle and X-Fort-TTL from response headers\n- Expose handle via FORT_HANDLE env var or stdout marker\n- Exit codes: 0=success, 1=http error, 2=auth error\n\nUsage: fort-agent-call \u003chost\u003e \u003ccapability\u003e [request-json]","acceptance_criteria":"- Can successfully call agent endpoints on other hosts\n- Properly signs requests\n- Extracts handle from response headers\n- Clear error codes for different failure modes","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:00:55.859422495Z","updated_at":"2025-12-30T22:00:55.859422495Z","dependencies":[{"issue_id":"fort-89e.3","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:00:55.868811639Z","created_by":"daemon"}]}
{"id":"fort-89e.4","title":"Mandatory agent endpoints","description":"Implement mandatory endpoints as bash handlers:\n- status: return {version, uptime, hostname}\n- manifest: return contents of /var/lib/fort/host-manifest.json\n- holdings: return contents of /var/lib/fort/holdings.json\n\nThese have no RBAC (any cluster host can call). Deploy agent to forge initially for testing.\n\nNote: release endpoint deferred to GC phase.","acceptance_criteria":"- All three endpoints return valid JSON\n- Endpoints work without RBAC restrictions\n- Agent deployed and functional on forge","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:01:29.957039978Z","updated_at":"2025-12-30T22:01:29.957039978Z","dependencies":[{"issue_id":"fort-89e.4","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:01:29.966238419Z","created_by":"daemon"},{"issue_id":"fort-89e.4","depends_on_id":"fort-89e.1","type":"blocks","created_at":"2025-12-30T22:07:00.24405932Z","created_by":"daemon"},{"issue_id":"fort-89e.4","depends_on_id":"fort-89e.2","type":"blocks","created_at":"2025-12-30T22:07:00.292343108Z","created_by":"daemon"},{"issue_id":"fort-89e.4","depends_on_id":"fort-89e.3","type":"blocks","created_at":"2025-12-30T22:07:00.344998156Z","created_by":"daemon"}]}
{"id":"fort-89e.5","title":"fort.needs / fort.capabilities option types","description":"Nix module options for declaring needs and capabilities:\n\nfort.needs.\u003ctype\u003e.\u003cname\u003e:\n- providers: list of hostnames\n- request: attrset passed to capability\n- store: path to store response (null = don't store)\n- restart: list of services to restart after fulfillment\n\nfort.capabilities.\u003cname\u003e:\n- handler: path to handler script\n- needsGC: bool (adds handle wrapper, GC timer)\n- description: human-readable\n\nGenerate:\n- /var/lib/fort/needs.json from all fort.needs declarations\n- /etc/fort-agent/rbac.json from capabilities + topology\n- Handler wrappers in /etc/fort-agent/handlers/\n\nMinimal implementation for slice 1 - can expand later.","acceptance_criteria":"- Options defined and documented\n- needs.json generated correctly\n- rbac.json generated from topology\n- Handlers installed in correct location","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:02:05.246179199Z","updated_at":"2025-12-30T22:02:05.246179199Z","dependencies":[{"issue_id":"fort-89e.5","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:02:05.256271649Z","created_by":"daemon"}]}
{"id":"fort-89e.6","title":"ssl-cert capability","description":"Handler on forge that returns SSL cert files:\n\nRequest: { domain: \"example.com\" } (or could be implicit from cluster)\nResponse: { cert: \"base64...\", key: \"base64...\", chain: \"base64...\" }\n\nReads from /var/lib/acme/\u003cdomain\u003e/ (existing ACME cert location).\nNo handle needed - certs are idempotent, no GC required.\n\nDeclare via fort.capabilities.ssl-cert in certificate-broker aspect.","acceptance_criteria":"- Handler returns valid cert data as JSON\n- Works with existing ACME-managed certs\n- Callable by any cluster host","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:02:34.465157032Z","updated_at":"2025-12-30T22:02:34.465157032Z","dependencies":[{"issue_id":"fort-89e.6","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:02:34.474996557Z","created_by":"daemon"},{"issue_id":"fort-89e.6","depends_on_id":"fort-89e.4","type":"blocks","created_at":"2025-12-30T22:07:00.535476723Z","created_by":"daemon"},{"issue_id":"fort-89e.6","depends_on_id":"fort-89e.5","type":"blocks","created_at":"2025-12-30T22:07:00.583681707Z","created_by":"daemon"}]}
{"id":"fort-89e.7","title":"fort-fulfill.service","description":"Systemd oneshot that runs on activation:\n\n1. Read /var/lib/fort/needs.json\n2. For each need where store path doesn't exist (or no handle file):\n   - Call provider via fort-agent-call\n   - On 2xx: store response at declared path, restart declared services\n   - On non-2xx: log warning, continue to next need\n3. Exit 0 even if some needs failed (best-effort)\n\nAdd fort-fulfill-retry.timer:\n- Runs every 5 minutes\n- Re-attempts any needs that haven't succeeded\n- Stops retrying once all needs fulfilled\n\nKey principle: fulfillment never blocks deploy.","acceptance_criteria":"- Service runs on activation\n- Successfully fulfilled needs have response stored\n- Failed needs logged but don't block\n- Retry timer re-attempts failures\n- Dependent services restarted after fulfillment","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:03:02.10662668Z","updated_at":"2025-12-30T22:03:02.10662668Z","dependencies":[{"issue_id":"fort-89e.7","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:03:02.115401513Z","created_by":"daemon"},{"issue_id":"fort-89e.7","depends_on_id":"fort-89e.3","type":"blocks","created_at":"2025-12-30T22:07:00.634767132Z","created_by":"daemon"},{"issue_id":"fort-89e.7","depends_on_id":"fort-89e.5","type":"blocks","created_at":"2025-12-30T22:07:00.681840919Z","created_by":"daemon"}]}
{"id":"fort-89e.8","title":"Migrate cert distribution to control plane","description":"Switch SSL cert distribution from rsync-push to agent-pull:\n\n1. Add fort.needs.ssl.wildcard to one test host (not forge/beacon)\n2. Verify cert arrives via fulfillment and nginx reloads\n3. Expand to all hosts\n4. Remove acme-sync timer from certificate-broker\n\nStorage: /var/lib/fort/ssl/\u003cdomain\u003e/{fullchain.pem,key.pem,chain.pem}\n\nThis is the first end-to-end validation of the control plane.","acceptance_criteria":"- All hosts receive certs via control plane\n- nginx reloads after cert delivery\n- acme-sync timer removed\n- No regressions in SSL functionality","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:03:06.345789733Z","updated_at":"2025-12-30T22:03:06.345789733Z","dependencies":[{"issue_id":"fort-89e.8","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:03:06.355981588Z","created_by":"daemon"},{"issue_id":"fort-89e.8","depends_on_id":"fort-89e.6","type":"blocks","created_at":"2025-12-30T22:07:00.727131406Z","created_by":"daemon"},{"issue_id":"fort-89e.8","depends_on_id":"fort-89e.7","type":"blocks","created_at":"2025-12-30T22:07:00.780444478Z","created_by":"daemon"}]}
{"id":"fort-89e.9","title":"git-token capability","description":"Handler on forge that creates/returns Forgejo deploy tokens:\n\nRequest: { host: \"ursula\", access: \"rw\" | \"ro\" }\nResponse: { token: \"...\" }\nHandle: yes (for GC when host removed)\n\nUses Forgejo API via forge-admin service account.\nReplaces forgejo-deploy-token-sync timer logic.\n\nRBAC: hosts with dev-sandbox aspect get rw, others get ro.","acceptance_criteria":"- Handler creates deploy token via Forgejo API\n- Returns handle for GC tracking\n- Token has correct access level based on request","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T22:03:29.654479207Z","updated_at":"2025-12-30T22:03:29.654479207Z","dependencies":[{"issue_id":"fort-89e.9","depends_on_id":"fort-89e","type":"parent-child","created_at":"2025-12-30T22:03:29.664203608Z","created_by":"daemon"},{"issue_id":"fort-89e.9","depends_on_id":"fort-89e.4","type":"blocks","created_at":"2025-12-30T22:07:00.949748126Z","created_by":"daemon"},{"issue_id":"fort-89e.9","depends_on_id":"fort-89e.5","type":"blocks","created_at":"2025-12-30T22:07:01.005000632Z","created_by":"daemon"}]}
{"id":"fort-8gl","title":"Improve deploy log visibility for agent collaboration","description":"Current friction: when agent runs deploy, token bloat + user can't review logs easily. When user runs deploy, agent can't see output. Explore options: CI/CD infra, tee to /tmp with standard filtering, or other patterns.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-21T14:22:00.169664-06:00","updated_at":"2025-12-27T19:43:36.363584454Z","closed_at":"2025-12-27T19:43:36.363584454Z","close_reason":"Superseded by CI/CD approach"}
{"id":"fort-99q","title":"Add 'just discover' task to trigger service registry","description":"Currently requires SSH to drhorrible to manually kick off service discovery. Add a just task for convenience.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-21T22:38:48.191652-06:00","updated_at":"2025-12-30T04:41:24.1308803Z","closed_at":"2025-12-30T04:41:24.1308803Z","close_reason":"Closed"}
{"id":"fort-9k0","title":"Investigate nix develop-based runner environment","description":"Explore using `nix develop` to provide runner dependencies from repo flake.\n\n## Problem\nCurrently the runner PATH is hardcoded in forge config. Adding/updating dependencies requires:\n1. Modifying forgejo app module\n2. Deploying to forge\n3. Restarting runner\n\nThis couples runner infrastructure to repo-specific needs (e.g., testing package updates).\n\n## Desired State\nWorkflows could declare their own dependencies via the repo devShell:\n\n```yaml\n- name: Run tests\n  run: nix develop -c ./run-tests.sh\n```\n\nOr the runner could automatically wrap commands in `nix develop`.\n\n## Investigation Areas\n- Can forgejo-runner be configured to wrap commands in `nix develop`?\n- Should we create a custom action that enters the devShell?\n- Performance implications of nix develop per-step vs per-job\n- Caching devShell dependencies\n\n## References\n- Current hardcoded PATH: apps/forgejo/default.nix runner config\n- Forgejo runner host execution model\n\n## Notes\nLow priority - current setup works, this is about flexibility for future needs.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-28T06:48:03.971366754Z","updated_at":"2025-12-28T06:48:03.971366754Z","labels":["runner investigation backlog"]}
{"id":"fort-9s5","title":"Set up ratched as dev sandbox host","description":"Configure ratched as the primary remote dev sandbox. Include: dev user with SSH access, claude-code, nix-direnv for per-project devshells, universal dev tools (git, ripgrep, fd, jq, tmux, neovim), and persistent /home.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-23T22:57:16.2191-06:00","updated_at":"2025-12-27T19:28:38.348752495Z","closed_at":"2025-12-27T19:28:38.348752495Z","close_reason":"Ratched dev environment is live and operational","dependencies":[{"issue_id":"fort-9s5","depends_on_id":"fort-4ih","type":"blocks","created_at":"2025-12-23T22:57:24.577545-06:00","created_by":"daemon"}]}
{"id":"fort-9w1","title":"Auto tmux attach in dev sandbox zshrc","description":"Add tmux auto-attach to zshrc for ratched dev sandbox. Must handle absent tmux sessions gracefully (don't fail if no session exists, create one or skip).","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-27T19:43:36.870634395Z","updated_at":"2025-12-27T19:57:42.5555827Z","closed_at":"2025-12-27T19:57:42.5555827Z","close_reason":"Closed"}
{"id":"fort-a68","title":"Add just task to trigger service-registry remotely","description":"## Problem\nCurrently requires manual SSH to drhorrible to run:\n```bash\nsystemctl start fort-service-registry.service\nsystemctl status fort-service-registry.service\n```\n\n## Solution\nAdd a Just task that:\n1. Infers the forge host from the cluster (whoever has the `forge` role)\n2. SSHs and triggers the service\n3. Waits and shows status output\n\nSomething like:\n```\njust sync-services\n```\n\n## Notes\n- Should use the SSH key from cluster manifest\n- Don't hardcode drhorrible - derive from role assignment","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T02:29:14.029129834Z","updated_at":"2025-12-28T07:04:09.673230201Z","closed_at":"2025-12-28T07:04:09.673230201Z","close_reason":"Closed","labels":["dx"]}
{"id":"fort-a8o","title":"Review/improve secrets management","description":"Current setup uses agenix with device key rotation. Areas to evaluate: secret rotation workflow, onboarding new secrets, whether KEYED_FOR_DEVICES pattern is optimal, documentation of secrets workflow.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-21T11:41:09.822948-06:00","updated_at":"2025-12-30T21:14:14.39105666Z","closed_at":"2025-12-30T21:14:14.39105666Z","close_reason":"Decided against Vault - agenix for static secrets, runtime fulfillment for dynamic credentials. No need for additional secrets management complexity."}
{"id":"fort-ax1","title":"Establish custom derivations pattern","description":"Define a consistent pattern/location for custom derivations. Currently Zot lives inline in apps/zot/default.nix. Options: dedicated pkgs/ or overlays/ directory, or keep inline. Should inform Termix and Pocket ID work.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-21T11:41:07.637411-06:00","updated_at":"2025-12-21T12:46:12.65483-06:00","closed_at":"2025-12-21T12:46:12.65483-06:00","close_reason":"Closed"}
{"id":"fort-bkv","title":"Typo in outline tmpfiles: fort-authy instead of fort-auth","description":"In apps/outline/default.nix, the tmpfiles rule has a typo:\n\n```nix\nsystemd.tmpfiles.rules = [\n  \"d /var/lib/fort-authy/outline 0700 outline outline -\"  # Should be fort-auth\n];\n```\n\nThis might be causing credential directory issues. Found during control plane design audit.","status":"open","priority":3,"issue_type":"bug","created_at":"2025-12-30T21:14:14.218020738Z","updated_at":"2025-12-30T21:14:14.218020738Z"}
{"id":"fort-c33","title":"Consolidate fortCluster options under fort.cluster","description":"Rename fortCluster.* options to fort.cluster.* (e.g., fort.cluster.exposedServices). Reduces magic globals and provides a single namespace for fort-specific NixOS options.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-21T12:18:03.246583-06:00","updated_at":"2025-12-21T12:18:03.246583-06:00"}
{"id":"fort-cbu","title":"Rename Justfile to lowercase justfile","description":"The filename is 'Justfile' but agents frequently try to read 'justfile'. Rename for consistency with common conventions.","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-28T14:59:53.442404902Z","updated_at":"2025-12-30T04:42:50.560226941Z","closed_at":"2025-12-30T04:42:50.560226941Z","close_reason":"Closed"}
{"id":"fort-cpg","title":"Add just to dev sandbox environment","description":"The dev sandbox (ratched) is missing `just` in PATH. This is needed for running common development commands like `just test` and `just deploy`.\n\nShould be added to the dev sandbox zshrc or nix environment.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T00:34:29.983542511Z","updated_at":"2025-12-28T06:51:36.089217499Z","closed_at":"2025-12-28T06:51:36.089217499Z","close_reason":"Closed"}
{"id":"fort-cy6","title":"CI/CD and GitOps Pipeline","description":"Implement a complete CI/CD and GitOps pipeline for fort-nix using Forgejo, Comin, and Attic.\n\n## Motivation\n\n- Enable Claude Code (on ratched devbox) to trigger deployments without root SSH access to production hosts\n- Separate secret authorship (editors) from secret decryption (production hosts)\n- Eliminate the need for a master deploy key\n- Add binary caching for faster deployments across heterogeneous architectures\n\n## Architecture Overview\n\n### Components\n- **Forgejo**: Self-hosted git forge on drhorrible (forge role) with Actions CI\n- **Comin**: Pull-based GitOps - hosts poll git and self-deploy\n- **Attic**: Binary cache - build once, substitute everywhere\n\n### Two-Branch Secrets Model\n- `main` branch: secrets keyed for editors only (laptop, ratched, forge)\n- `release` branch: CI re-keys secrets for actual host recipients\n- Hosts run comin against `release` branch\n\n### Key Design Decisions\n- Forge (drhorrible) stays on manual deploy-rs - it's critical infrastructure\n- All hosts can read AND write to Attic cache (content-addressing makes poisoning infeasible)\n- CI builds all hosts best-effort, targets fill cache gaps via post-deploy hook\n- deploy-rs kept as escape hatch for high-risk changes\n\n## Reference\nSee recommendation.md for full details.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-27T23:48:47.590858803Z","updated_at":"2025-12-30T04:35:43.956655665Z","closed_at":"2025-12-30T04:35:43.956655665Z","close_reason":"Closed"}
{"id":"fort-cy6.1","title":"Add Forgejo app to forge role","description":"Create a Forgejo app module and add it to the forge role on drhorrible.\n\n## Context\nForgejo is a self-hosted git forge (Gitea fork) that will serve as our CI/CD hub. It runs on drhorrible alongside existing forge services (CoreDNS, Zot, Prometheus/Grafana/Loki).\n\n## Implementation\n\n### Create the app module\nCreate `apps/forgejo/default.nix`:\n\n```nix\n{ config, lib, pkgs, ... }:\nlet\n  cfg = config.fort;\n  domain = cfg.clusterManifest.domain;\nin {\n  services.forgejo = {\n    enable = true;\n    database.type = \"sqlite3\";\n    settings = {\n      server = {\n        DOMAIN = \"git.${domain}\";\n        ROOT_URL = \"https://git.${domain}/\";\n        HTTP_PORT = 3001;  # Avoid conflict with Grafana on 3000\n      };\n      service = {\n        DISABLE_REGISTRATION = true;  # SSO only\n      };\n      # Session/security settings TBD based on SSO integration\n    };\n  };\n\n  # Expose via fortCluster.exposedServices\n  fort.exposedServices.forgejo = {\n    port = 3001;\n    subdomain = \"git\";\n    visibility = \"vpn\";  # or \"public\" if needed externally\n    sso = \"oidc\";  # integrate with pocket-id\n  };\n}\n```\n\n### Add to forge role\nUpdate `roles/forge.nix` to include forgejo in the apps list.\n\n### Persistence\nForgejo data should persist at `/persist/system/var/lib/forgejo` (impermanence pattern).\n\n## Acceptance Criteria\n- [ ] Forgejo service starts on drhorrible\n- [ ] Web UI accessible at git.fort.gisi.network (via mesh)\n- [ ] Data persists across reboots\n\n## Notes\n- SSO configuration will be handled in a follow-up ticket\n- Runner setup is also a separate ticket","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:49:13.162017945Z","updated_at":"2025-12-28T02:02:16.93298591Z","closed_at":"2025-12-28T02:02:16.93298591Z","close_reason":"Closed","labels":["forgejo","phase-1"],"dependencies":[{"issue_id":"fort-cy6.1","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:49:13.172306649Z","created_by":"daemon"}]}
{"id":"fort-cy6.10","title":"Configure hosts to use Attic cache","description":"Configure all hosts to substitute from the Attic binary cache.\n\n## Context\nWith Attic running on forge, all hosts should be configured to pull pre-built derivations from the cache instead of building locally.\n\n**Critical for CI**: The Forgejo runner is the primary cache consumer AND producer. When CI runs `nix flake check`, it:\n1. Pulls existing derivations from cache (avoids hammering cache.nixos.org)\n2. Builds anything missing\n3. Pushes new builds back to cache\n\nThis means CI naturally warms the cache - a separate \"build for cache\" step is unnecessary.\n\n## Implementation\n\n### Create shared cache configuration\nAdd to common configuration (e.g., in `common/host.nix` or a new aspect):\n\n```nix\n{ config, lib, pkgs, ... }:\nlet\n  cfg = config.fort;\n  domain = cfg.clusterManifest.domain;\nin {\n  nix.settings = {\n    substituters = [\n      \"https://cache.nixos.org\"\n      \"https://cache.${domain}\"\n    ];\n    \n    trusted-public-keys = [\n      \"cache.nixos.org-1:6NCHdD59X431o0gWypbMrAURkbJ16ZPMQFGspcDShjY=\"\n      \"cache.${domain}-1:XXXXX...\"  # Replace with actual key from fort-cy6.9\n    ];\n    \n    trusted-users = [ \"root\" \"@wheel\" ];\n  };\n}\n```\n\n### CI Runner Configuration\nThe forge host runs the CI runner, so it gets cache config automatically. Additionally, configure the runner's nix to push builds:\n\n```nix\n# In forgejo app or forge role\nnix.settings.post-build-hook = pkgs.writeScript \"upload-to-cache\" ''\n  #!${pkgs.bash}/bin/bash\n  set -euf\n  if [ -n \"${OUT_PATHS:-}\" ]; then\n    ${pkgs.attic-client}/bin/attic push fort-cache $OUT_PATHS\n  fi\n'';\n```\n\nThis makes every CI build automatically populate the cache.\n\n### Push capability for other hosts\nFor the multi-writer model, hosts also need push tokens (stored in agenix).\n\n## Acceptance Criteria\n- [ ] All hosts have cache.gisi.network in substituters\n- [ ] CI runner pulls from cache (verify cache hits in logs)\n- [ ] CI runner pushes builds to cache (post-build hook)\n- [ ] Subsequent CI runs are faster due to cache hits\n\n## Dependencies\n- fort-cy6.9: Attic must be deployed and cache created\n\n## Notes\n- The public key will be known after Attic setup\n- CI becomes the primary cache warmer - no separate build job needed\n- Monitor cache hit rates via Attic metrics","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:54:29.467595091Z","updated_at":"2025-12-28T20:42:20.242964522Z","closed_at":"2025-12-28T20:42:20.242964522Z","close_reason":"Closed","labels":["attic","cache","phase-3"],"dependencies":[{"issue_id":"fort-cy6.10","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:54:29.47729488Z","created_by":"daemon"},{"issue_id":"fort-cy6.10","depends_on_id":"fort-cy6.9","type":"blocks","created_at":"2025-12-27T23:54:29.481056235Z","created_by":"daemon"}]}
{"id":"fort-cy6.11","title":"Configure CI runner to use Attic cache","description":"Configure the Forgejo Actions runner to both pull from and push to the Attic binary cache.\n\n## Context\nThe CI runner is the ideal place to warm the cache. Every `nix flake check` run:\n1. Evaluates all host configurations\n2. Builds derivations (with `--no-build` we skip this, but release builds will)\n3. Should pull from our cache first (avoid hammering cache.nixos.org)\n4. Should push new builds back to cache\n\n## Implementation\n\n### 1. Configure Nix substituters\nThe forge host already gets this from cy6.10 common config, but verify the runner inherits it.\n\n### 2. Add post-build hook for cache push\nIn the forgejo app module, add a post-build hook that pushes to Attic.\n\n### 3. Configure Attic credentials for runner\nThe runner needs a push token stored in agenix.\n\n### 4. Add attic-client to runner PATH\nUpdate the runner config.yml PATH to include attic-client.\n\n## Acceptance Criteria\n- [ ] CI pulls from Attic cache (check logs for cache hits)\n- [ ] CI pushes successful builds to Attic\n- [ ] Subsequent CI runs show improved cache hit rate\n- [ ] cache.nixos.org requests reduced\n\n## Dependencies\n- fort-cy6.9: Attic must be deployed\n- fort-cy6.5: CI workflow must exist\n\n## Notes\n- The post-build hook runs for ALL nix builds on forge, not just CI\n- This is actually desirable - any build on forge warms the cache","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:55:18.201841246Z","updated_at":"2025-12-28T20:42:20.292305072Z","closed_at":"2025-12-28T20:42:20.292305072Z","close_reason":"Closed","labels":["attic","ci","phase-3"],"dependencies":[{"issue_id":"fort-cy6.11","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:55:18.213848738Z","created_by":"daemon"},{"issue_id":"fort-cy6.11","depends_on_id":"fort-cy6.9","type":"blocks","created_at":"2025-12-27T23:55:18.218122686Z","created_by":"daemon"},{"issue_id":"fort-cy6.11","depends_on_id":"fort-cy6.7","type":"blocks","created_at":"2025-12-27T23:55:18.219737614Z","created_by":"daemon"}]}
{"id":"fort-cy6.12","title":"Test binary cache flow","description":"Verify the binary cache is working correctly before enabling GitOps.\n\n## Context\nBefore hosts auto-deploy via comin, we need to confirm:\n1. CI builds push to cache\n2. Hosts can substitute from cache\n3. Cache hits are logged/observable\n\n## Test Cases\n\n### Test 1: CI pushes to cache\n1. Push a change to main\n2. Watch release workflow\n3. Verify build step completes\n4. Check Attic UI/CLI for new store paths\n\n```bash\nattic cache info fort-cache\n# Should show increased path count after CI run\n```\n\n### Test 2: Host substitutes from cache\nOn a test host (e.g., ratched):\n\n```bash\n# Clear local store of a known-cached path (carefully!)\n# Or just try building something that CI already built\n\n# Check substitution\nnix build /nix/store/xxx... --dry-run\n# Should show \"will be fetched from https://cache.fort.gisi.network\"\n\n# Actually build\nnix build ./path/to/something\n# Should download from cache, not build locally\n```\n\n### Test 3: Cache miss builds locally\n1. Find a derivation that CI didn't build (e.g., different arch)\n2. Build on target host\n3. Verify it builds locally\n4. (Phase 4 will add push-back to cache)\n\n### Test 4: Monitor cache metrics\nIf Attic exposes metrics:\n- Check Prometheus for cache hit/miss rates\n- Verify Grafana dashboard shows cache usage\n\n## Acceptance Criteria\n- [ ] CI workflow pushes at least one host build to cache\n- [ ] At least one host successfully substitutes from cache\n- [ ] Cache hit shows in nix logs (--print-build-logs or similar)\n- [ ] No errors in Attic service logs\n\n## Dependencies\n- fort-cy6.10: Hosts configured with substituters\n- fort-cy6.11: CI pushes to cache\n\n## Notes\n- This is the gate before Phase 4 (GitOps)\n- Document cache hit rates for future reference\n- Consider adding cache monitoring to observability stack","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:55:35.35082255Z","updated_at":"2025-12-28T22:45:46.009696312Z","closed_at":"2025-12-28T22:45:46.009696312Z","close_reason":"Closed","labels":["attic","phase-3","testing"],"dependencies":[{"issue_id":"fort-cy6.12","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:55:35.360227142Z","created_by":"daemon"},{"issue_id":"fort-cy6.12","depends_on_id":"fort-cy6.10","type":"blocks","created_at":"2025-12-27T23:55:35.363639816Z","created_by":"daemon"},{"issue_id":"fort-cy6.12","depends_on_id":"fort-cy6.11","type":"blocks","created_at":"2025-12-27T23:55:35.365071817Z","created_by":"daemon"}]}
{"id":"fort-cy6.13","title":"Create comin GitOps aspect","description":"Create a comin aspect for pull-based GitOps deployment.\n\n## Context\nComin is a NixOS deployment tool that operates in pull mode - hosts poll a git repo and deploy their own configuration. This eliminates the need for a central deployer with SSH access to all hosts.\n\n## Implementation\n\n### Add comin to flake inputs\nUpdate root `flake.nix`:\n\n```nix\n{\n  inputs = {\n    # ... existing inputs ...\n    comin = {\n      url = \"github:nlewo/comin\";\n      inputs.nixpkgs.follows = \"nixpkgs\";\n    };\n  };\n  \n  outputs = { self, nixpkgs, comin, ... }: {\n    # ... existing outputs ...\n  };\n}\n```\n\n### Create aspect\nCreate `aspects/gitops/default.nix`:\n\n```nix\n{ config, lib, pkgs, inputs, ... }:\nlet\n  cfg = config.fort;\n  domain = cfg.clusterManifest.domain;\nin {\n  imports = [ inputs.comin.nixosModules.comin ];\n\n  services.comin = {\n    enable = true;\n    \n    remotes = [{\n      name = \"origin\";\n      url = \"https://git.${domain}/infra/fort-nix.git\";\n      \n      branches.main = {\n        name = \"release\";  # Pull from release branch, not main\n      };\n      \n      # Optional: testing branch for safe experimentation\n      # branches.testing = {\n      #   name = \"testing\";\n      # };\n    }];\n    \n    # Poll interval\n    # interval = 60;  # seconds, default is 60\n    \n    # Machine identification\n    # By default, uses hostname to find its config\n  };\n}\n```\n\n### Flake structure for comin\nComin expects `nixosConfigurations.\u003chostname\u003e` at the flake root or a specified path. Our current structure has configs in host subflakes. Options:\n\n1. **Export from root flake**: Add `nixosConfigurations` to root flake that re-exports from host flakes\n2. **Configure comin path**: Point comin to the host-specific flake\n\nOption 1 is cleaner for comin:\n\n```nix\n# In root flake.nix\noutputs = { ... }: {\n  nixosConfigurations = {\n    ratched = (import ./clusters/bedlam/hosts/ratched/flake.nix).nixosConfigurations.ratched;\n    # ... other hosts\n  };\n};\n```\n\n### Authentication\nComin needs to fetch from Forgejo. Options:\n- Public read access to release branch\n- Deploy key with read-only access\n- Token-based authentication\n\nFor simplicity, consider making the release branch publicly readable (contains no secrets that hosts can't decrypt anyway).\n\n## Acceptance Criteria\n- [ ] Comin aspect module created\n- [ ] Can be added to host manifest\n- [ ] Comin service starts without errors\n- [ ] Comin can fetch from Forgejo (may need auth setup)\n\n## Dependencies\n- fort-cy6.12: Cache should be working first\n\n## Notes\n- Start with ratched (dev sandbox) for testing\n- Do NOT add to forge (drhorrible) - it stays on manual deploy\n- See recommendation.md for full rationale","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:56:13.512683383Z","updated_at":"2025-12-29T04:05:15.107224624Z","closed_at":"2025-12-29T04:05:15.107224624Z","close_reason":"Closed","labels":["comin","gitops","phase-4"],"dependencies":[{"issue_id":"fort-cy6.13","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:56:13.518647597Z","created_by":"daemon"},{"issue_id":"fort-cy6.13","depends_on_id":"fort-cy6.12","type":"blocks","created_at":"2025-12-27T23:56:13.522693099Z","created_by":"daemon"}]}
{"id":"fort-cy6.14","title":"Deploy comin to joker (test host)","description":"Deploy comin to ratched as the first GitOps-enabled host.\n\n## Context\nRatched is the dev sandbox - low risk, easy to recover if something breaks. It's the ideal first host for GitOps.\n\n## Implementation\n\n### Update ratched manifest\nEdit `clusters/bedlam/hosts/ratched/manifest.nix`:\n\n```nix\n{\n  hostName = \"ratched\";\n  deviceUuid = \"...\";\n  \n  roles = [];\n  \n  apps = [];\n  \n  aspects = [\n    \"mesh\"\n    \"observable\"\n    \"dev-sandbox\"\n    \"gitops\"  # Add this\n  ];\n}\n```\n\n### Initial deploy via deploy-rs\nThe first deploy must be via deploy-rs (chicken-and-egg: comin isn't installed yet):\n\n```bash\njust deploy ratched\n```\n\n### Verify comin is running\nAfter deploy:\n\n```bash\nssh root@ratched.fort.gisi.network\n\n# Check service status\nsystemctl status comin\n\n# Check logs\njournalctl -u comin -f\n\n# Comin should be polling and showing \"no changes\" or similar\n```\n\n### Test a change\n1. Make a small change to ratched's config (e.g., add a comment)\n2. Push to main\n3. Wait for CI to update release branch\n4. Watch comin logs on ratched\n5. Verify the change is applied\n\n## Acceptance Criteria\n- [ ] Comin service running on ratched\n- [ ] Comin successfully polls Forgejo\n- [ ] Comin detects and applies a test change\n- [ ] No manual intervention needed for the test change\n\n## Dependencies\n- fort-cy6.13: Comin aspect must be created\n\n## Notes\n- If comin breaks ratched, we can still SSH in and fix manually\n- Or use deploy-rs as fallback\n- This validates the entire pipeline before rolling out to other hosts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:56:30.002650682Z","updated_at":"2025-12-29T04:05:15.159188871Z","closed_at":"2025-12-29T04:05:15.159188871Z","close_reason":"Closed","labels":["comin","gitops","phase-4"],"dependencies":[{"issue_id":"fort-cy6.14","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:56:30.012473934Z","created_by":"daemon"},{"issue_id":"fort-cy6.14","depends_on_id":"fort-cy6.13","type":"blocks","created_at":"2025-12-27T23:56:30.01606146Z","created_by":"daemon"}]}
{"id":"fort-cy6.15","title":"Add post-build cache push hook","description":"Configure hosts to push their builds back to Attic cache after successful deployment.\n\n## Context\nFor heterogeneous architectures, CI may not be able to build everything. Hosts that build locally should push their results to cache so future builds (on any host of that arch) get cache hits.\n\n## Implementation\n\n### Option A: Comin post-deploy hook\nComin supports post-deploy commands:\n\n```nix\nservices.comin = {\n  # ... existing config ...\n\n  postBuildCommand = '\n    ${pkgs.attic-client}/bin/attic push fort-cache \"$out\"\n  ';\n};\n```\n\nThis pushes the built system closure after successful activation.\n\n### Option B: Nix post-build-hook\nGlobal hook for ALL nix builds:\n\n```nix\nnix.settings.post-build-hook = pkgs.writeScript \"upload-to-cache\" '\n  #\\!/bin/bash\n  set -euf\n\n  if [ -n \"${OUT_PATHS:-}\" ]; then\n    echo \"Pushing to cache: $OUT_PATHS\"\n    attic push fort-cache $OUT_PATHS || true\n  fi\n';\n```\n\n### Authentication\nEach host needs a push token for Attic. Options:\n\n1. **Shared write token**: All hosts use the same token (simpler)\n2. **Per-host tokens**: Each host has its own token (more auditable)\n\nFor homelab, Option 1 is fine. Store token in agenix and configure attic client.\n\n### Recommendation\nUse Option A (comin hook) for GitOps hosts - only pushes system builds, not every random build.\n\nKeep Option B available as an aspect for hosts that do a lot of local building.\n\n## Acceptance Criteria\n- [ ] Hosts can push to Attic cache\n- [ ] After comin deploys, built paths appear in cache\n- [ ] Subsequent builds on other hosts of same arch get cache hits\n\n## Dependencies\n- fort-cy6.13: Comin aspect needed\n- fort-cy6.10: Hosts need Attic client configured\n\n## Notes\n- This completes the multi-writer cache model\n- First ARM host to deploy will populate ARM cache for all ARM hosts\n- Monitor cache growth - may need garbage collection tuning","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:58:46.149670638Z","updated_at":"2025-12-29T19:23:02.926041198Z","closed_at":"2025-12-29T19:23:02.926041198Z","close_reason":"Closed","labels":["attic","comin","phase-4"],"dependencies":[{"issue_id":"fort-cy6.15","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:58:46.159878071Z","created_by":"daemon"},{"issue_id":"fort-cy6.15","depends_on_id":"fort-cy6.13","type":"blocks","created_at":"2025-12-27T23:58:46.163700898Z","created_by":"daemon"},{"issue_id":"fort-cy6.15","depends_on_id":"fort-cy6.10","type":"blocks","created_at":"2025-12-27T23:58:46.165341456Z","created_by":"daemon"}]}
{"id":"fort-cy6.16","title":"Test GitOps end-to-end flow","description":"Comprehensive test of the complete GitOps pipeline before rolling out to more hosts.\n\n## Context\nBefore enabling comin on production hosts, verify the entire flow works:\n1. Push to main\n2. CI builds + re-keys → release branch\n3. Comin pulls release on ratched\n4. Ratched deploys and pushes to cache\n\n## Test Scenario\n\n### Make a visible change\nAdd something observable to ratched's config:\n\n```nix\n# In ratched's config, add:\nenvironment.etc.\"gitops-test\".text = \"deployed at: ${builtins.currentTime}\";\n# Or simpler: add a systemd service, a package, etc.\n```\n\n### Execute the test\n\n1. **Commit and push to main**\n   ```bash\n   git add .\n   git commit -m \"Test GitOps flow\"\n   git push origin main\n   ```\n\n2. **Watch CI** (Forgejo Actions)\n   - Flake check passes\n   - Build step runs (may use cache)\n   - Re-key step runs\n   - Release branch updated\n\n3. **Watch comin on ratched**\n   ```bash\n   ssh root@ratched.fort.gisi.network\n   journalctl -u comin -f\n   # Should see: pull, evaluate, build, activate\n   ```\n\n4. **Verify change applied**\n   ```bash\n   cat /etc/gitops-test\n   # Should show the file we added\n   ```\n\n5. **Verify cache populated**\n   ```bash\n   attic cache info fort-cache\n   # Should show ratched's paths\n   ```\n\n### Timing\nNote the time from push to activation. This is your deployment latency:\n- CI time: ~X minutes\n- Comin poll interval: up to 60s\n- Build time: depends on cache hits\n- Total: ~Y minutes\n\n## Failure Scenarios to Test\n\n### Test: What if CI fails?\n- Push a change that breaks flake check\n- Verify release branch is NOT updated\n- Verify ratched stays on previous config\n\n### Test: What if comin build fails?\n- Push a change that evaluates but fails to build\n- Verify ratched stays on previous config\n- Check comin logs for error\n\n### Test: Manual rollback\n- If needed, how to manually fix ratched?\n- `nixos-rebuild switch` or deploy-rs should still work\n\n## Acceptance Criteria\n- [ ] Change flows from push → ratched without manual intervention\n- [ ] Deployment time is acceptable (\u003c 10 minutes?)\n- [ ] Failed changes don't break ratched\n- [ ] Manual recovery path confirmed working\n\n## Dependencies\n- fort-cy6.14: Comin deployed to ratched\n- fort-cy6.15: Post-build hook configured\n\n## Notes\n- This is the gate before production rollout\n- Document any issues for future reference\n- Consider adding alerting for comin failures","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:59:08.283025585Z","updated_at":"2025-12-29T04:17:48.761245696Z","closed_at":"2025-12-29T04:17:48.761245696Z","close_reason":"Closed","labels":["gitops","phase-4","testing"],"dependencies":[{"issue_id":"fort-cy6.16","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:59:08.293134677Z","created_by":"daemon"},{"issue_id":"fort-cy6.16","depends_on_id":"fort-cy6.14","type":"blocks","created_at":"2025-12-27T23:59:08.296807129Z","created_by":"daemon"},{"issue_id":"fort-cy6.16","depends_on_id":"fort-cy6.15","type":"blocks","created_at":"2025-12-27T23:59:08.298362491Z","created_by":"daemon"}]}
{"id":"fort-cy6.17","title":"Roll out comin to remaining hosts","description":"Enable GitOps on remaining hosts (except forge).\n\n## Context\nAfter validating GitOps on ratched, roll out to other hosts incrementally.\n\n## Hosts to Enable\n\nEnable comin on (in suggested order):\n1. **joker** - minimal node, low risk\n2. **ursula** - media server\n3. **lordhenry** - LLM stack\n4. **minos** - IoT hub (more complex, test carefully)\n5. **q** - ingest machine (many services)\n6. **raishan** - beacon (public-facing, do last among these)\n\n## DO NOT Enable\n- **drhorrible (forge)** - stays on manual deploy-rs (critical infrastructure)\n\n## Rollout Process\n\nFor each host:\n\n1. **Update manifest**\n   ```nix\n   aspects = [\n     # ... existing aspects ...\n     \"gitops\"\n   ];\n   ```\n\n2. **Deploy via deploy-rs** (first time)\n   ```bash\n   just deploy \u003chostname\u003e\n   ```\n\n3. **Verify comin running**\n   ```bash\n   ssh root@\u003chostname\u003e.fort.gisi.network\n   systemctl status comin\n   ```\n\n4. **Test a change**\n   Push a small change, verify it propagates\n\n5. **Monitor for issues**\n   Check logs, verify services healthy\n\n### Rollback Plan\nIf a host has issues:\n1. SSH in (should still work)\n2. `systemctl stop comin` to prevent further changes\n3. Fix via `nixos-rebuild switch` or deploy-rs\n4. Investigate root cause before re-enabling\n\n## Acceptance Criteria\n- [ ] All hosts (except forge) running comin\n- [ ] All hosts successfully deploying from release branch\n- [ ] No manual intervention needed for normal changes\n- [ ] Forge confirmed to still work with deploy-rs\n\n## Dependencies\n- fort-cy6.16: E2E test must pass first\n\n## Notes\n- Take it slow - one host at a time\n- Have a rollback plan ready\n- Monitor for a few days before considering complete\n- Update documentation with new deployment workflow","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:59:26.664584628Z","updated_at":"2025-12-29T21:46:07.493628169Z","closed_at":"2025-12-29T21:46:07.493628169Z","close_reason":"Closed","labels":["comin","gitops","phase-4"],"dependencies":[{"issue_id":"fort-cy6.17","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:59:26.674063868Z","created_by":"daemon"},{"issue_id":"fort-cy6.17","depends_on_id":"fort-cy6.16","type":"blocks","created_at":"2025-12-27T23:59:26.677698788Z","created_by":"daemon"}]}
{"id":"fort-cy6.18","title":"Grant Claude Code push access to Forgejo","description":"Configure Claude Code on ratched to push to Forgejo without exposing sensitive credentials.\n\n## Context\nThe goal of this entire initiative: Claude Code can trigger deployments by pushing to git, without having SSH access to production hosts or the ability to decrypt production secrets.\n\n## Implementation\n\n### Authentication Options\n\n1. **Personal Access Token**\n   - Create a Forgejo PAT for \"claude-code\" user\n   - Store on ratched (can be in plain file - it only grants git push)\n   - Configure git credential helper\n\n2. **SSH Deploy Key**\n   - Generate SSH key on ratched\n   - Add public key to Forgejo as deploy key with write access\n   - Configure git to use this key\n\n3. **OIDC-based auth** (if supported)\n   - More complex but more secure\n\n### Recommended: Personal Access Token\n\nOn ratched:\n```bash\n# Store token (created via Forgejo UI)\necho \"token_here\" \u003e /persist/system/home/dev/.forgejo-token\nchmod 600 /persist/system/home/dev/.forgejo-token\n\n# Configure git\ngit config --global credential.helper store\n# Or use a credential helper that reads from file\n```\n\nIn NixOS config:\n```nix\n# Ensure git is configured for the dev user\nhome-manager.users.dev = {\n  programs.git = {\n    enable = true;\n    extraConfig = {\n      credential.helper = \"store --file=/persist/system/home/dev/.forgejo-token\";\n    };\n  };\n};\n```\n\n### Create Forgejo User\n- Create \"claude-code\" user in Forgejo\n- Grant write access to fort-nix repo\n- Generate PAT with repo write scope\n\n### Permissions Audit\nVerify Claude Code on ratched has:\n- [x] Push access to Forgejo (this ticket)\n- [x] Editor key for main branch secrets\n- [ ] NO SSH access to other hosts\n- [ ] NO access to production secrets (only editor-keyed)\n- [ ] NO access to FORGE_AGE_KEY\n\n## Acceptance Criteria\n- [ ] Claude Code can `git push` to Forgejo\n- [ ] Push triggers CI workflow\n- [ ] No additional credentials exposed to Claude Code\n\n## Dependencies\n- fort-cy6.17: GitOps must be working first\n\n## Notes\n- This is the final piece that enables autonomous Claude Code deployments\n- Token should be rotatable without system changes\n- Consider audit logging of pushes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:59:55.004948365Z","updated_at":"2025-12-29T22:15:06.973476772Z","closed_at":"2025-12-29T22:15:06.973476772Z","close_reason":"Closed","labels":["phase-5","security"],"dependencies":[{"issue_id":"fort-cy6.18","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:59:55.014227504Z","created_by":"daemon"},{"issue_id":"fort-cy6.18","depends_on_id":"fort-cy6.17","type":"blocks","created_at":"2025-12-27T23:59:55.017562567Z","created_by":"daemon"}]}
{"id":"fort-cy6.19","title":"Document deployment workflows","description":"Document the new deployment workflows and when to use each.\n\n## Context\nWith GitOps enabled, there are now multiple ways to deploy. Document when to use each.\n\n## Documentation to Create/Update\n\n### Update README.md or create DEPLOYING.md\n\n```markdown\n# Deployment Workflows\n\n## GitOps (Default)\nMost hosts auto-deploy via comin when changes are pushed to main.\n\n1. Make changes\n2. Push to main\n3. CI validates and updates release branch\n4. Hosts pull and deploy automatically\n\nAffected hosts: all except drhorrible (forge)\n\n## Manual Deploy (Forge Only)\nForge (drhorrible) requires manual deployment:\n\n\\`\\`\\`bash\njust deploy drhorrible\n\\`\\`\\`\n\n## Manual Deploy (Emergency/Override)\nFor any host, you can still use deploy-rs:\n\n\\`\\`\\`bash\njust deploy \u003chostname\u003e\n\\`\\`\\`\n\nUse this when:\n- GitOps is broken\n- You need immediate deployment (don't want to wait for CI)\n- Testing changes before committing\n\n## High-Risk Changes\nFor changes that might break SSH/network:\n\n1. Use comin's testing branch feature\n2. Or deploy manually with deploy-rs (has rollback)\n3. Have console access ready\n\n## Monitoring Deployments\n- Forgejo Actions: https://git.fort.gisi.network/infra/fort-nix/actions\n- Comin logs: \\`journalctl -u comin -f\\` on each host\n- Grafana: deployment metrics (if configured)\n```\n\n### Update Justfile comments\nAdd comments explaining when to use `just deploy` vs GitOps.\n\n### Update recommendation.md\nMark as implemented, add lessons learned.\n\n## Acceptance Criteria\n- [ ] Deployment documentation exists\n- [ ] Clear guidance on when to use each method\n- [ ] Emergency procedures documented\n- [ ] Team knows about the new workflow\n\n## Dependencies\n- fort-cy6.17: GitOps must be rolled out first\n\n## Notes\n- Keep it concise - developers won't read walls of text\n- Include troubleshooting tips\n- Link to relevant logs/dashboards","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T00:00:13.749704412Z","updated_at":"2025-12-29T22:31:55.671371074Z","closed_at":"2025-12-29T22:31:55.671371074Z","close_reason":"Closed","labels":["docs","phase-5"],"dependencies":[{"issue_id":"fort-cy6.19","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-28T00:00:13.758309846Z","created_by":"daemon"},{"issue_id":"fort-cy6.19","depends_on_id":"fort-cy6.17","type":"blocks","created_at":"2025-12-28T00:00:13.761624549Z","created_by":"daemon"}]}
{"id":"fort-cy6.2","title":"Configure Forgejo SSO via pocket-id","description":"Configure Forgejo to authenticate via pocket-id (the existing OIDC provider).\n\n## Context\npocket-id is already deployed on drhorrible and provides OIDC authentication backed by LLDAP. Forgejo needs to be configured as an OIDC client.\n\n## Implementation\n\n### Register Forgejo as OIDC client in pocket-id\nAdd Forgejo client configuration to pocket-id. The redirect URI will be:\n`https://git.gisi.network/user/oauth2/pocket-id/callback`\n\n### Configure Forgejo OIDC\nUpdate `apps/forgejo/default.nix` to add OIDC settings:\n\n```nix\nservices.forgejo.settings = {\n  # ... existing settings ...\n  \n  oauth2_client = {\n    ENABLE_AUTO_REGISTRATION = true;\n    USERNAME = \"preferred_username\";  # or \"email\"\n    ACCOUNT_LINKING = \"auto\";\n  };\n};\n```\n\nThe actual OIDC provider configuration may need to be done via Forgejo admin UI or database seeding, since it includes secrets (client_id, client_secret).\n\n### Secrets\n- Create `apps/forgejo/oidc-secret.age` with the OIDC client secret\n\n## Acceptance Criteria\n- [ ] Users can log in to Forgejo via pocket-id\n- [ ] No local registration (SSO-only)\n- [ ] User accounts auto-created on first login\n\n## Notes\n- May need to configure group-based authorization later\n- Consider admin user bootstrapping strategy\n\nLabels: [forgejo phase-1 sso]","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:49:27.524565897Z","updated_at":"2025-12-28T03:27:02.065472508Z","closed_at":"2025-12-28T03:27:02.065472508Z","close_reason":"Closed","labels":["forgejo","phase-1","sso"],"dependencies":[{"issue_id":"fort-cy6.2","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:49:27.533675547Z","created_by":"daemon"},{"issue_id":"fort-cy6.2","depends_on_id":"fort-cy6.1","type":"blocks","created_at":"2025-12-27T23:49:27.537271627Z","created_by":"daemon"}]}
{"id":"fort-cy6.20","title":"Verify deploy-rs still works as escape hatch","description":"Confirm deploy-rs remains functional as an escape hatch for manual deployments.\n\n## Context\nEven with GitOps, we need deploy-rs to work for:\n- Forge (drhorrible) - always manual\n- Emergency overrides on any host\n- High-risk changes where you want rollback protection\n\n## Verification\n\n### Test on forge\n```bash\njust deploy drhorrible\n```\n- Should work as before\n- This is the primary deployment method for forge\n\n### Test on a GitOps host\n```bash\njust deploy ratched\n```\n- Should still work\n- Comin and deploy-rs can coexist\n- deploy-rs does immediate push, comin will eventually converge\n\n### Verify rollback still works\n1. Deploy a change that breaks SSH (test carefully!)\n2. Verify deploy-rs rolls back automatically\n3. Host should remain accessible\n\n### Check for conflicts\n- Comin polling shouldn't interfere with deploy-rs\n- If both try to activate simultaneously, one should win cleanly\n\n## Acceptance Criteria\n- [ ] `just deploy drhorrible` works\n- [ ] `just deploy \u003cgitops-host\u003e` works\n- [ ] No conflicts between comin and deploy-rs\n- [ ] Rollback protection functional on deploy-rs deploys\n\n## Dependencies\n- fort-cy6.17: GitOps must be rolled out first\n\n## Notes\n- deploy-rs uses SSH, comin uses git pull - different mechanisms\n- Keep Justfile deploy commands working\n- This is insurance against GitOps failures","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T00:00:33.63959393Z","updated_at":"2025-12-29T22:26:33.604104361Z","closed_at":"2025-12-29T22:26:33.604104361Z","close_reason":"Closed","labels":["phase-5","testing"],"dependencies":[{"issue_id":"fort-cy6.20","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-28T00:00:33.648712989Z","created_by":"daemon"},{"issue_id":"fort-cy6.20","depends_on_id":"fort-cy6.17","type":"blocks","created_at":"2025-12-28T00:00:33.651953456Z","created_by":"daemon"}]}
{"id":"fort-cy6.21","title":"Support comin test branches with secret re-keying","description":"## Context\n\nComin supports a pattern where pushing to a `host-test` branch lets the host pull and run the config without updating the boot generation. This is useful for testing changes before committing to them.\n\nHowever, with the two-branch secrets model, `main` (and branches off main) are keyed for editors only. Hosts can't decrypt those secrets directly.\n\n## Proposed Solution\n\nCreate a workflow that:\n1. Watches for pushes to `*-test-rekey` branches (e.g., `minos-test-rekey`)\n2. Re-keys secrets for the target host\n3. Pushes to the corresponding `*-test` branch (e.g., `minos-test`)\n\nThis lets developers push experimental changes to `host-test-rekey` and have CI produce a decryptable `host-test` branch for comin to pull.\n\n## Alternatives Considered\n\n- Could require devs to manually re-key for test deploys (annoying)\n- Could have a single `test-rekey` branch that CI fans out to per-host test branches (complex)\n\n## Dependencies\n- fort-cy6.7: Release workflow (establishes the re-keying pattern)\n- fort-cy6.13: Comin aspect (hosts need comin to use test branches)\n\n## Notes\n- Naming TBD: `host-test-rekey` vs `test/host` vs something else\n- May want to auto-cleanup stale test branches","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T07:21:46.574313228Z","updated_at":"2025-12-29T23:24:28.991432291Z","closed_at":"2025-12-29T23:24:28.991432291Z","close_reason":"Closed","dependencies":[{"issue_id":"fort-cy6.21","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-28T07:21:46.575809539Z","created_by":"daemon"}]}
{"id":"fort-cy6.22","title":"Consolidate key definitions in cluster manifest","description":"## Context\n\nThe cluster manifest has overlapping key definitions that evolved organically:\n\n- `sshKey.publicKey` - primary laptop deploy key\n- `authorizedDeployKeys` - additional deploy keys (added to root authorized_keys AND secrets)\n- `privilegedKeys` - keys that can decrypt secrets on main branch\n- `ciAgeKey` - CI-specific key\n\n## Cleanup Options\n\n1. Merge `sshKey.publicKey` into `privilegedKeys` (already duplicated there)\n2. Clarify purpose of `authorizedDeployKeys` vs `privilegedKeys`\n3. Consider whether `authorizedDeployKeys` should only affect SSH access, not secret decryption\n\n## Notes\nLow priority cleanup after CI/CD pipeline is stable.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T08:09:57.615598545Z","updated_at":"2025-12-30T04:01:38.260941252Z","closed_at":"2025-12-30T04:01:38.260948426Z","dependencies":[{"issue_id":"fort-cy6.22","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-28T08:09:57.616975844Z","created_by":"daemon"}]}
{"id":"fort-cy6.22.1","title":"Update manifest.nix with principals structure","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T03:47:15.694679037Z","updated_at":"2025-12-30T03:48:23.675872115Z","closed_at":"2025-12-30T03:48:23.675876784Z","dependencies":[{"issue_id":"fort-cy6.22.1","depends_on_id":"fort-cy6.22","type":"parent-child","created_at":"2025-12-30T03:47:15.704752326Z","created_by":"daemon"}]}
{"id":"fort-cy6.22.2","title":"Update secrets.nix to derive from principals","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T03:47:15.890745828Z","updated_at":"2025-12-30T03:50:09.03872924Z","closed_at":"2025-12-30T03:50:09.038733478Z","dependencies":[{"issue_id":"fort-cy6.22.2","depends_on_id":"fort-cy6.22","type":"parent-child","created_at":"2025-12-30T03:47:15.892171597Z","created_by":"daemon"}]}
{"id":"fort-cy6.22.3","title":"Update host.nix to derive root authorized_keys","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T03:47:16.091349425Z","updated_at":"2025-12-30T03:51:11.272209655Z","closed_at":"2025-12-30T03:51:11.272214154Z","dependencies":[{"issue_id":"fort-cy6.22.3","depends_on_id":"fort-cy6.22","type":"parent-child","created_at":"2025-12-30T03:47:16.09221078Z","created_by":"daemon"}]}
{"id":"fort-cy6.22.4","title":"Update dev-sandbox and remove private key","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T03:47:16.278835838Z","updated_at":"2025-12-30T03:55:24.757372876Z","closed_at":"2025-12-30T03:55:24.757377134Z","dependencies":[{"issue_id":"fort-cy6.22.4","depends_on_id":"fort-cy6.22","type":"parent-child","created_at":"2025-12-30T03:47:16.279750808Z","created_by":"daemon"}]}
{"id":"fort-cy6.22.5","title":"Update Justfile to derive from admin principal","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T03:47:16.478081197Z","updated_at":"2025-12-30T03:55:46.080042561Z","closed_at":"2025-12-30T03:55:46.080048744Z","dependencies":[{"issue_id":"fort-cy6.22.5","depends_on_id":"fort-cy6.22","type":"parent-child","created_at":"2025-12-30T03:47:16.479370891Z","created_by":"daemon"}]}
{"id":"fort-cy6.22.6","title":"Remove obsolete key fields from manifest","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T03:47:16.69196144Z","updated_at":"2025-12-30T04:01:38.206569996Z","closed_at":"2025-12-30T04:01:38.206575096Z","dependencies":[{"issue_id":"fort-cy6.22.6","depends_on_id":"fort-cy6.22","type":"parent-child","created_at":"2025-12-30T03:47:16.692839367Z","created_by":"daemon"}]}
{"id":"fort-cy6.23","title":"Exhaustive cache sanity check","description":"Full end-to-end validation of binary cache flow after GitOps rollout is complete.\n\n## Checks\n- Verify CI pushes for all host architectures\n- Confirm substitution logs on multiple hosts\n- Check Attic metrics/logs for error rates\n- Document observed cache hit rates\n\n## Context\nDeferred from fort-cy6.12 - adjacent logs during development gave confidence, but worth a thorough check once everything is stable.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-28T22:45:39.128879389Z","updated_at":"2025-12-30T03:02:01.32131697Z","closed_at":"2025-12-30T03:02:01.32131697Z","close_reason":"Closed","dependencies":[{"issue_id":"fort-cy6.23","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-28T22:45:39.129938712Z","created_by":"daemon"}]}
{"id":"fort-cy6.24","title":"Optimize release workflow: only re-key changed secrets","description":"Currently the release workflow re-keys ALL secrets on every commit. Since age uses random nonces, this produces different ciphertext every time, causing all hosts to see 'changes' and re-evaluate even when their config hasn't changed.\n\n## Optimization\n\n1. Build map of secret path → recipients (already done)\n2. Store this map in the release branch (e.g., `.release-recipients.json`)\n3. On next run, compare current map to stored map\n4. Only re-key secrets whose recipients have changed\n5. Update stored map\n\n## Benefits\n\n- Hosts only see derivation changes when their secrets actually changed\n- Reduces unnecessary evaluation/build cycles\n- More efficient use of cache (unchanged derivations stay cached)\n\n## Notes\n\n- Low priority - current overhead is minimal (eval is fast, builds are cached)\n- But easy win for cleaner semantics","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-29T04:16:37.21179604Z","updated_at":"2025-12-29T23:00:48.149199633Z","closed_at":"2025-12-29T23:00:48.149199633Z","close_reason":"Closed","dependencies":[{"issue_id":"fort-cy6.24","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-29T04:16:37.221050799Z","created_by":"daemon"}]}
{"id":"fort-cy6.25","title":"Consolidate host-manifest.json and services.json","description":"The new host-manifest.json includes apps, aspects, and roles. We should extend it to also include exposedServices and update service-registry to read from this single manifest instead of having two redundant files (services.json and host-manifest.json).","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-29T21:57:53.04155595Z","updated_at":"2025-12-30T04:35:35.475662186Z","closed_at":"2025-12-30T04:35:35.475662186Z","close_reason":"Closed","dependencies":[{"issue_id":"fort-cy6.25","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-29T21:57:53.050913199Z","created_by":"daemon"}]}
{"id":"fort-cy6.26","title":"Reorder CI: validate before rekey","description":"Currently the CI workflow has 'rekey for release branch' and 'validate the build' as separate jobs. The rekey should only happen after validation passes - no point rekeying secrets for a build that won't work.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-29T22:00:13.915937453Z","updated_at":"2025-12-29T22:59:30.762870608Z","closed_at":"2025-12-29T22:59:30.762870608Z","close_reason":"Closed","dependencies":[{"issue_id":"fort-cy6.26","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-29T22:00:13.92610488Z","created_by":"daemon"}]}
{"id":"fort-cy6.3","title":"Mirror fort-nix repo to Forgejo","description":"Set up fort-nix repository in Forgejo, either as a mirror of the existing remote or as the new primary.\n\n## Context\nfort-nix currently lives on an external git remote. We need it in Forgejo to enable CI/CD via Forgejo Actions.\n\n## Options\n\n### Option A: Mirror (recommended for transition)\n- Create repo in Forgejo\n- Set up as mirror of existing remote\n- Keeps external remote as source of truth during transition\n- Forgejo Actions can run on push events\n\n### Option B: Primary (eventual goal)\n- Create repo in Forgejo as primary\n- Update all developers' remotes\n- External remote becomes backup/mirror\n\n## Implementation\n\n### Create repository\nVia Forgejo web UI or API:\n- Organization: `infra` (create if needed)\n- Repository: `fort-nix`\n- Visibility: Private (VPN-only access anyway)\n\n### Configure as mirror (Option A)\n```bash\n# In Forgejo admin: Settings → Mirror → Add mirror\n# Source: existing git remote URL\n# Sync interval: e.g., every 10 minutes\n```\n\n### Or configure as primary (Option B)\n```bash\ngit remote set-url origin https://git.gisi.network/infra/fort-nix.git\n# Or add as additional remote during transition:\ngit remote add forgejo https://git.gisi.network/infra/fort-nix.git\n```\n\n### Authentication\n- Push access requires authentication\n- Options: SSH keys, personal access tokens, or OIDC-integrated git credential helper\n\n## Acceptance Criteria\n- [ ] fort-nix repo exists in Forgejo\n- [ ] Repository contains current main branch\n- [ ] Can push to Forgejo (at least from laptop/ratched)\n\n## Dependencies\n- fort-cy6.2: SSO should be configured so users can authenticate\n\n## Notes\n- Consider setting up a deploy key for CI operations\n- Branch protection rules can be configured later\n\nLabels: [forgejo phase-1]","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:49:47.492597329Z","updated_at":"2025-12-28T05:10:34.388950209Z","closed_at":"2025-12-28T05:10:34.388950209Z","close_reason":"Closed","labels":["forgejo","phase-1"],"dependencies":[{"issue_id":"fort-cy6.3","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:49:47.501796394Z","created_by":"daemon"},{"issue_id":"fort-cy6.3","depends_on_id":"fort-cy6.2","type":"blocks","created_at":"2025-12-27T23:49:47.504977102Z","created_by":"daemon"}]}
{"id":"fort-cy6.4","title":"Set up Forgejo Actions runner","description":"Configure a Forgejo Actions runner on drhorrible to execute CI workflows.\n\n## Context\nForgejo Actions is GitHub Actions-compatible CI. It requires a runner daemon to execute workflows. The runner will run on drhorrible (forge) alongside Forgejo itself.\n\n## Implementation\n\n### Enable Actions in Forgejo\nUpdate `apps/forgejo/default.nix`:\n\n```nix\nservices.forgejo.settings = {\n  # ... existing settings ...\n  actions = {\n    ENABLED = true;\n  };\n};\n```\n\n### Configure Runner\nUse the NixOS gitea-actions-runner service with forgejo-runner package:\n\n```nix\nservices.gitea-actions-runner = {\n  package = pkgs.forgejo-runner;\n  instances.default = {\n    enable = true;\n    name = \"forge-runner\";\n    url = \"https://git.gisi.network\";\n    tokenFile = config.age.secrets.forgejo-runner-token.path;\n    labels = [\n      \"nixos:host\"          # Native NixOS runner\n      \"x86_64-linux:host\"   # Architecture label\n    ];\n    settings = {\n      # Runner settings\n      capacity = 2;  # Parallel jobs\n    };\n  };\n};\n```\n\n### Secrets\n- Create runner registration token via Forgejo admin UI\n- Store in `apps/forgejo/runner-token.age`\n- Add to agenix configuration\n\n### Nix in Runner Environment\nThe runner needs Nix available for CI jobs. Options:\n1. Use `nixos:host` label and run directly on host (has Nix already)\n2. Use container with Nix installed\n\nOption 1 is simpler for our use case since we're building NixOS configs.\n\n### Runner Capabilities\nThe runner will need:\n- Nix with flakes enabled\n- Network access to cache.nixos.org and our Attic cache (once set up)\n- Ability to run `nix build`, `nix flake check`, etc.\n\n## Acceptance Criteria\n- [ ] Runner appears in Forgejo admin → Actions → Runners\n- [ ] Runner shows as online\n- [ ] Test workflow executes successfully (e.g., simple `nix flake check`)\n\n## Dependencies\n- fort-cy6.1: Forgejo must be deployed first\n\n## Notes\n- Runner token needs to be generated after Forgejo is running\n- Consider adding more runners later for parallelism or different arches\n- Docker/Podman not required if using host labels\n\nLabels: [ci forgejo phase-1]","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:50:05.470953583Z","updated_at":"2025-12-28T05:59:46.152522046Z","closed_at":"2025-12-28T05:59:46.152522046Z","close_reason":"Closed","labels":["ci","forgejo","phase-1"],"dependencies":[{"issue_id":"fort-cy6.4","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:50:05.484171456Z","created_by":"daemon"},{"issue_id":"fort-cy6.4","depends_on_id":"fort-cy6.1","type":"blocks","created_at":"2025-12-27T23:50:05.487740544Z","created_by":"daemon"}]}
{"id":"fort-cy6.5","title":"Create flake check CI workflow","description":"Create a Forgejo Actions workflow that runs `nix flake check` on pull requests and pushes.\n\n## Context\nThis is the basic CI validation workflow. It ensures the flake evaluates correctly before changes are merged.\n\n## Implementation\n\n### Create workflow file\nCreate `.forgejo/workflows/check.yml`:\n\n```yaml\nname: Flake Check\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  check:\n    runs-on: nixos\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Check root flake\n        run: nix flake check --no-build\n\n      - name: Check host flakes\n        run: |\n          for host_dir in clusters/bedlam/hosts/*/; do\n            host=$(basename \"$host_dir\")\n            echo \"::group::Checking host: $host\"\n            nix flake check \"$host_dir\" --no-build\n            echo \"::endgroup::\"\n          done\n\n      - name: Check device flakes\n        run: |\n          for device_dir in clusters/bedlam/devices/*/; do\n            device=$(basename \"$device_dir\")\n            echo \"::group::Checking device: $device\"\n            nix flake check \"$device_dir\" --no-build\n            echo \"::endgroup::\"\n          done\n```\n\n### Notes on `--no-build`\nUsing `--no-build` speeds up checks by only evaluating, not building. Full builds happen in the release workflow.\n\n### Runner Requirements\n- Runner must have Nix with flakes enabled\n- Uses `nixos` label to run on host runner\n\n## Acceptance Criteria\n- [ ] Workflow triggers on push to main\n- [ ] Workflow triggers on PRs to main\n- [ ] All flake checks pass on current main\n- [ ] Failed checks block PR merge (once branch protection configured)\n\n## Dependencies\n- fort-cy6.4: Runner must be set up\n- fort-cy6.3: Repo must be in Forgejo\n\n## Notes\n- This mirrors `just test` functionality\n- Consider caching Nix store between runs for speed","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:50:33.356495967Z","updated_at":"2025-12-28T06:05:19.457392982Z","closed_at":"2025-12-28T06:05:19.457392982Z","close_reason":"Closed","labels":["ci","phase-2"],"dependencies":[{"issue_id":"fort-cy6.5","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:50:33.366873446Z","created_by":"daemon"},{"issue_id":"fort-cy6.5","depends_on_id":"fort-cy6.4","type":"blocks","created_at":"2025-12-27T23:50:33.370196133Z","created_by":"daemon"},{"issue_id":"fort-cy6.5","depends_on_id":"fort-cy6.3","type":"blocks","created_at":"2025-12-27T23:50:33.371588495Z","created_by":"daemon"}]}
{"id":"fort-cy6.6","title":"Refactor secrets.nix for editor-only keys","description":"Refactor secrets.nix to use editor-only keys on the main branch, enabling the two-branch secrets model.\n\n## Context\nCurrently, secrets are keyed for all devices and re-keyed at deploy time. For GitOps, we need:\n- **main branch**: secrets keyed for editors only (laptop, ratched, forge)\n- **release branch**: CI re-keys for actual host recipients\n\nThis separates secret authorship (editors can decrypt on main) from production access (only hosts can decrypt on release).\n\n## Current State\n`secrets.nix` currently defines `publicKeys` per-secret, including device keys when `KEYED_FOR_DEVICES=1`.\n\n## Implementation\n\n### Define editor keys\n```nix\nlet\n  # Keys that can decrypt secrets on main branch\n  editors = [\n    clusterManifest.sshPublicKey                    # Laptop (primary deploy key)\n    devices.\"\u003cratched-uuid\u003e\".sshPublicKey           # Dev sandbox\n    devices.\"\u003cdrhorrible-uuid\u003e\".sshPublicKey        # Forge (needs to re-key)\n  ];\nin {\n  # All secrets use editors only\n  \"aspects/mesh/auth-key.age\".publicKeys = editors;\n  \"apps/homeassistant/secrets.yaml.age\".publicKeys = editors;\n  # ... all other secrets\n}\n```\n\n### Remove KEYED_FOR_DEVICES logic\nThe deploy-time rekeying with `KEYED_FOR_DEVICES=1` is no longer needed for GitOps hosts. Keep deploy-rs functional for forge (manual deploys), but the release workflow handles rekeying for comin hosts.\n\n### Re-encrypt all secrets\nAfter updating secrets.nix:\n```bash\nagenix -r  # Re-key all secrets for new recipients\n```\n\n### Update .gitignore / pre-commit\nEnsure secrets are only committed with editor keys (never device keys on main).\n\n## Acceptance Criteria\n- [ ] All secrets in main branch keyed only for editors\n- [ ] Laptop can decrypt all secrets\n- [ ] Ratched can decrypt all secrets  \n- [ ] Forge (drhorrible) can decrypt all secrets\n- [ ] Production hosts CANNOT decrypt secrets on main branch\n- [ ] deploy-rs still works for forge (manual deploy)\n\n## Dependencies\n- fort-cy6.1: Forge's SSH key must be known\n\n## Security Considerations\n- This is a security-sensitive change\n- Verify editor list is correct before re-keying\n- Old commits in git history will still have device-keyed secrets (acceptable)\n\n## Notes\n- This is foundational for the release workflow\n- Claude Code on ratched gains ability to author/edit secrets\n- Claude Code still cannot decrypt production secrets (those only exist on release branch)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T23:52:19.969746559Z","updated_at":"2025-12-28T07:58:47.347576258Z","closed_at":"2025-12-28T07:58:47.347576258Z","close_reason":"Closed","labels":["phase-2","secrets"],"dependencies":[{"issue_id":"fort-cy6.6","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:52:19.979260963Z","created_by":"daemon"},{"issue_id":"fort-cy6.6","depends_on_id":"fort-cy6.1","type":"blocks","created_at":"2025-12-27T23:52:19.982437154Z","created_by":"daemon"}]}
{"id":"fort-cy6.7","title":"Create release workflow with secret re-keying","description":"Create the Forgejo Actions workflow that re-keys secrets for host recipients and pushes to the release branch.\n\n## Context\nThis is the core of the two-branch secrets model:\n1. Developer pushes to main (secrets keyed for editors)\n2. CI inspects each host's agenix config to determine which secrets it needs\n3. CI re-keys those secrets for the host's public key\n4. CI pushes to release branch\n5. Hosts (via comin) pull from release and can decrypt their secrets\n\n## Implementation\n\n### Create workflow file\nCreate `.forgejo/workflows/release.yml`:\n\n```yaml\nname: Build and Release\n\non:\n  push:\n    branches: [main]\n\njobs:\n  release:\n    runs-on: nixos\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0  # Need full history for branch operations\n\n      - name: Determine per-host secrets\n        run: |\n          mkdir -p /tmp/host-secrets\n          for host in $(nix eval .#hosts --json 2\u003e/dev/null | jq -r 'keys[]' || echo \"\"); do\n            echo \"Analyzing secrets for $host...\"\n            nix eval \".#nixosConfigurations.$host.config.age.secrets\" --json 2\u003e/dev/null \\\n              | jq -r 'to_entries[] | .value.file' \\\n              | sort -u \u003e \"/tmp/host-secrets/$host.txt\" || echo \"No secrets for $host\"\n          done\n\n      - name: Re-key secrets for recipients\n        env:\n          FORGE_AGE_KEY: ${{ secrets.FORGE_AGE_KEY }}\n        run: |\n          echo \"$FORGE_AGE_KEY\" \u003e /tmp/forge-key.txt\n          trap 'rm -f /tmp/forge-key.txt' EXIT\n          \n          for host in $(ls /tmp/host-secrets/); do\n            host=\"${host%.txt}\"\n            echo \"::group::Re-keying for $host\"\n            \n            hostKey=$(nix eval \".#hosts.$host.device.sshPublicKey\" --raw 2\u003e/dev/null || echo \"\")\n            if [ -z \"$hostKey\" ]; then\n              echo \"::warning::Could not get key for $host, skipping\"\n              continue\n            fi\n            \n            while IFS= read -r secret; do\n              [ -z \"$secret\" ] \u0026\u0026 continue\n              echo \"Re-keying: $secret\"\n              # Decrypt with forge key, re-encrypt for host\n              age -d -i /tmp/forge-key.txt \"$secret\" \\\n                | age -e -r \"$hostKey\" -o \"$secret.new\" \\\n                \u0026\u0026 mv \"$secret.new\" \"$secret\"\n            done \u003c \"/tmp/host-secrets/$host.txt\"\n            \n            echo \"::endgroup::\"\n          done\n\n      - name: Commit and push release branch\n        run: |\n          git config user.name \"Forge CI\"\n          git config user.email \"forge@fort.gisi.network\"\n          \n          git checkout -B release\n          git add -A\n          git commit -m \"Release: $(git rev-parse --short main) - $(date -Iseconds)\" \\\n            || echo \"No changes to commit\"\n          git push -f origin release\n```\n\n### Secrets Required\n- `FORGE_AGE_KEY`: Forge's age private key (for decrypting editor-keyed secrets)\n\nStore in Forgejo repository secrets (Settings → Secrets).\n\n### Getting Host List\nThe workflow assumes `.#hosts` exports a list of hosts. This may need adjustment based on flake structure. Alternative:\n```bash\nls clusters/bedlam/hosts/\n```\n\n### Getting Host Public Keys\nAssumes `.#hosts.$host.device.sshPublicKey` is accessible. May need to expose this in the flake or read from device manifest files.\n\n## Acceptance Criteria\n- [ ] Workflow triggers on push to main\n- [ ] Release branch is created/updated\n- [ ] Secrets in release branch are keyed for correct hosts\n- [ ] Forge can still decrypt secrets on main branch\n- [ ] Hosts can decrypt their secrets on release branch\n\n## Dependencies\n- fort-cy6.5: Check workflow should pass first\n- fort-cy6.6: Secrets must be refactored to editor-only\n\n## Security Considerations\n- FORGE_AGE_KEY is highly sensitive - it can decrypt all secrets\n- Stored only in Forgejo secrets, never in repo\n- Runner should not log secret contents\n\n## Notes\n- The exact nix eval paths may need adjustment based on flake structure\n- Consider adding the build step here once Attic is set up (Phase 3)\n- May want to add a \"dry-run\" mode for testing","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T23:53:05.370399023Z","updated_at":"2025-12-28T07:58:47.288229687Z","closed_at":"2025-12-28T07:58:47.288229687Z","close_reason":"Closed","labels":["ci","phase-2","secrets"],"dependencies":[{"issue_id":"fort-cy6.7","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:53:05.380428876Z","created_by":"daemon"},{"issue_id":"fort-cy6.7","depends_on_id":"fort-cy6.5","type":"blocks","created_at":"2025-12-27T23:53:05.383967205Z","created_by":"daemon"},{"issue_id":"fort-cy6.7","depends_on_id":"fort-cy6.6","type":"blocks","created_at":"2025-12-27T23:53:05.385388765Z","created_by":"daemon"}]}
{"id":"fort-cy6.8","title":"Test CI pipeline end-to-end","description":"Verify the complete CI pipeline works correctly before proceeding to cache and GitOps phases.\n\n## Context\nBefore adding binary caching and comin, we need to verify:\n1. Check workflow runs on PRs\n2. Release workflow creates properly-keyed release branch\n3. Secrets are correctly re-keyed for each host\n\n## Test Cases\n\n### Test 1: Check workflow on PR\n1. Create a branch with a minor change\n2. Open PR against main\n3. Verify check workflow triggers and passes\n4. Verify checks block merge if they fail\n\n### Test 2: Release workflow on merge\n1. Merge the PR to main\n2. Verify release workflow triggers\n3. Verify release branch is created/updated\n\n### Test 3: Secret re-keying verification\nFor each host, verify the secrets in release branch are correctly keyed:\n\n```bash\n# Checkout release branch\ngit checkout release\n\n# For a test host (e.g., ratched), try decrypting a secret\n# This should FAIL on main branch (editor keys only)\n# This should SUCCEED on release branch (host key)\n\n# On the target host, or with the host's private key:\nage -d -i /path/to/host/key aspects/mesh/auth-key.age\n```\n\n### Test 4: Editor access on main\nVerify editors can still decrypt on main:\n```bash\ngit checkout main\nage -d -i ~/.ssh/id_ed25519 aspects/mesh/auth-key.age  # Should work\n```\n\n### Test 5: Host cannot decrypt main\nVerify hosts cannot decrypt main branch secrets:\n```bash\ngit checkout main\nage -d -i /path/to/host/key aspects/mesh/auth-key.age  # Should FAIL\n```\n\n## Acceptance Criteria\n- [ ] Check workflow passes on current main\n- [ ] Release branch exists after push to main\n- [ ] At least one host's secrets verified to be correctly keyed on release\n- [ ] Editors confirmed able to decrypt main branch secrets\n- [ ] Hosts confirmed unable to decrypt main branch secrets\n\n## Dependencies\n- fort-cy6.7: Release workflow must be implemented\n\n## Notes\n- Document any issues found for future reference\n- This is a gate before proceeding to Phase 3\n- Consider automating these tests as part of the pipeline","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:53:26.367461113Z","updated_at":"2025-12-28T14:55:38.457706872Z","closed_at":"2025-12-28T14:55:38.457706872Z","close_reason":"Closed","labels":["phase-2","testing"],"dependencies":[{"issue_id":"fort-cy6.8","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:53:26.377412823Z","created_by":"daemon"},{"issue_id":"fort-cy6.8","depends_on_id":"fort-cy6.7","type":"blocks","created_at":"2025-12-27T23:53:26.380536572Z","created_by":"daemon"}]}
{"id":"fort-cy6.9","title":"Add Attic binary cache to forge","description":"Deploy Attic binary cache server on drhorrible (forge).\n\n## Status: IN PROGRESS - Deploy pending\n\n### Completed\n- [x] Add attic flake input to root flake.nix\n- [x] Update all host flakes to follow root/attic\n- [x] Update common/host.nix to import atticd NixOS module\n- [x] Create apps/attic/default.nix with services.atticd config\n- [x] Add attic to forge role\n- [x] Generate and encrypt server token secret\n- [x] Create bootstrap service for cache/token creation\n- [x] Update Justfile template for new hosts\n- [x] Document Service Initialization patterns in AGENTS.md\n- [x] Fix forgejo binary rename (gitea -\u003e forgejo) broken by nixpkgs update\n- [x] Add pkgs.attic-client to attic bootstrap path\n\n### Pending\n- [ ] Debug atticd startup failure (exit code 101)\n- [ ] Successful deploy to drhorrible\n- [ ] Verify cache accessible at cache.gisi.network\n- [ ] Test pushing a derivation to cache\n\n### Known Issues\nThe first deploy attempt failed with:\n1. **atticd.service exit 101** - Unknown cause, need to check logs after next deploy\n2. **forgejo-bootstrap gitea not found** - Fixed (binary renamed to `forgejo` in nixos-25.11)\n3. **Tailscale state corruption** - Side effect of failed deploy, fixed by clearing state\n\nThe nixpkgs was also updated from 2025-10-14 to 2025-12-06 as a side effect of adding the attic input (host lock files were fully updated rather than just adding new input).\n\n### Files Changed\n- flake.nix, flake.lock (attic input)\n- common/host.nix (import atticd module)\n- apps/attic/default.nix, apps/attic/attic-server-token.age (new)\n- apps/forgejo/default.nix (gitea -\u003e forgejo binary)\n- roles/forge.nix (add attic)\n- Justfile (template update)\n- AGENTS.md (Service Initialization docs)\n- secrets.nix (attic secret)\n- All host flake.nix and flake.lock files\n\n### Next Steps\n1. Deploy to drhorrible (user will do this)\n2. Check `journalctl -u atticd -n 50` for startup error\n3. Fix atticd config issue if needed\n4. Verify bootstrap creates cache and tokens","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:54:07.515511079Z","updated_at":"2025-12-28T20:07:28.034231214Z","closed_at":"2025-12-28T20:07:28.034231214Z","close_reason":"Closed","labels":["attic","cache","phase-3"],"dependencies":[{"issue_id":"fort-cy6.9","depends_on_id":"fort-cy6","type":"parent-child","created_at":"2025-12-27T23:54:07.527240706Z","created_by":"daemon"},{"issue_id":"fort-cy6.9","depends_on_id":"fort-cy6.8","type":"blocks","created_at":"2025-12-27T23:54:07.530875725Z","created_by":"daemon"}]}
{"id":"fort-eax","title":"Increase Nix download-buffer-size for hosts","description":"During the attic deploy, download buffer was noted as full causing slow downloads. Consider adding nix.settings.download-buffer-size to hosts to improve large package downloads.","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-28T15:38:02.099786945Z","updated_at":"2025-12-30T04:41:24.191470535Z","closed_at":"2025-12-30T04:41:24.191470535Z","close_reason":"Closed"}
{"id":"fort-ee2","title":"Create claude-users LDAP group in lldap","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T21:15:50.927493-06:00","updated_at":"2025-12-21T22:20:30.130349-06:00","closed_at":"2025-12-21T22:20:30.130349-06:00","close_reason":"User added claude-users group to ldap-groups.age"}
{"id":"fort-efv","title":"Remove claude-code-ui internal auth once groups restriction works","description":"Once fort-040 (oauth2-proxy groups claim) is fixed, disable or bypass the internal username/password auth in claude-code-ui. VPN + gatekeeper + groups should be sufficient.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T00:30:13.582813-06:00","updated_at":"2025-12-27T19:31:29.179784772Z","closed_at":"2025-12-27T19:31:29.179784772Z","close_reason":"Won't do - claude-code-ui being deprovisioned entirely","dependencies":[{"issue_id":"fort-efv","depends_on_id":"fort-040","type":"blocks","created_at":"2025-12-22T00:30:18.458525-06:00","created_by":"daemon"}]}
{"id":"fort-eir","title":"Ensure claude-code-ui user has access to git","description":"The claude-code-ui service user needs git access to work with repositories.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T01:22:05.465709-06:00","updated_at":"2025-12-22T01:30:13.080958-06:00","closed_at":"2025-12-22T01:30:13.080958-06:00","close_reason":"Already implemented - git is in the service path at line 76"}
{"id":"fort-fh7","title":"Deploy Claude Code UI to q host","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T21:08:48.459214-06:00","updated_at":"2025-12-22T01:01:28.249789-06:00","closed_at":"2025-12-22T01:01:28.249789-06:00","close_reason":"Claude Code UI fully deployed - VPN + gatekeeper auth + internal auth working, Claude OAuth complete"}
{"id":"fort-gel","title":"Add Termix as hosted app on q","description":"Deploy Termix (github.com/Termix-SSH/Termix) on q host. Fast-moving project, likely needs custom derivation. SSH-based terminal sharing tool.","notes":"## Resolution: VPN-only + Internal Auth\n\nAfter investigating Termix OIDC (v1.9.0):\n- OIDC still requires Admin UI configuration (no env var support)\n- No reverse proxy auth header support (no X-Forwarded-User, etc.)\n- Internal auth cannot be disabled\n\nDecision: Deploy behind Tailscale VPN (visibility: vpn, which is default), using Termix's built-in authentication.\n\n### Implementation\n- OCI container: ghcr.io/lukegus/termix:latest (via zot proxy)\n- Port 8080\n- Data persistence: /var/lib/termix:/data\n- Service: termix. (VPN-only access)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-21T11:41:07.941134-06:00","updated_at":"2025-12-22T23:00:23.77283-06:00","closed_at":"2025-12-22T23:00:23.77283-06:00","close_reason":"Implemented with VPN-only visibility + internal auth approach","dependencies":[{"issue_id":"fort-gel","depends_on_id":"fort-ax1","type":"blocks","created_at":"2025-12-21T11:41:22.692611-06:00","created_by":"daemon"}]}
{"id":"fort-kl1","title":"Age files must be committed before deploy to avoid revert","description":"When age files are modified but not committed, the deploy process may revert them due to rekeying logic. This is a footgun for operators.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-21T22:20:30.351213-06:00","updated_at":"2025-12-30T07:10:50.781189701Z","closed_at":"2025-12-30T07:10:50.781189701Z","close_reason":"Closed"}
{"id":"fort-nrx","title":"Install beads in claude-code-ui context","description":"Install beads (https://github.com/steveyegge/beads) in the claude-code-ui context. This will likely require creating a custom Go derivation and making it available to the service user.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T01:22:05.746585-06:00","updated_at":"2025-12-27T19:31:17.891936161Z","closed_at":"2025-12-27T19:31:17.891936161Z","close_reason":"Won't do - claude-code-ui approach abandoned in favor of direct ratched dev environment"}
{"id":"fort-okx","title":"Set up Gitea for self-hosted git","description":"Deploy Gitea (or similar) for self-hosted git. Prereq for CI/CD pipelines.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:43:36.513587843Z","updated_at":"2025-12-28T02:15:42.546528778Z","closed_at":"2025-12-28T02:15:42.546528778Z","close_reason":"Closed"}
{"id":"fort-qg0","title":"Complete attic bootstrap script","description":"The attic server runs, but the bootstrap script (ExecStartPost) that creates admin/CI tokens and the cache needs work. Issues encountered:\n- atticadm needs a config file with all required fields (chunking, etc.)\n- Config must match what atticd uses\n- Consider using the same config generation approach as the nixpkgs module\n\nReference: apps/attic/default.nix ExecStartPost section","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T19:59:39.31863417Z","updated_at":"2025-12-28T20:26:02.407846254Z","closed_at":"2025-12-28T20:26:02.407846254Z","close_reason":"Closed"}
{"id":"fort-qz3","title":"Add 'just diagnose \u003chost\u003e' helper","description":"Create a non-interactive diagnostic command that pulls common debug info from a host: failed systemd units, recent journal errors, disk space, memory, etc. Useful for agents who can't use interactive SSH.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T12:18:02.974999-06:00","updated_at":"2025-12-30T07:13:52.295155608Z","closed_at":"2025-12-30T07:13:52.295155608Z","close_reason":"Less useful now that most hosts use GitOps autodeploy, and agents lack SSH credentials for journal access anyway."}
{"id":"fort-ucz","title":"Add default nginx vhost with deploy status endpoint","description":"Add a default nginx virtual host on port 80 that serves a simple status page showing:\n\n- Deploy timestamp\n- Git SHA / version\n- Host name\n- Maybe uptime or other quick health indicators\n\nThis provides a fast way to verify deploy status without authentication (VPN-gated only).\n\n## Implementation notes\n\n- May require moving some services off port 80 to a different port (nginx can proxy them)\n- Should be part of the base host config (common/ or an aspect)\n- Could be a static JSON file generated at activation time, or a simple systemd service\n- `visibility: local` so it's VPN-only\n\n## Example output\n\n```json\n{\n  \"host\": \"joker\",\n  \"deployed_at\": \"2025-12-29T10:30:00Z\",\n  \"git_sha\": \"abc123f\",\n  \"uptime_seconds\": 3600\n}\n```","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-29T22:40:29.065471823Z","updated_at":"2025-12-30T07:38:37.238580539Z","closed_at":"2025-12-30T07:38:37.238580539Z","close_reason":"Closed"}
{"id":"fort-xeb","title":"Document service registry OIDC provisioning flow","description":"The dummy-creds-then-real-creds flow via service-registry is non-intuitive. Add docs to AGENTS.md or README explaining: 1) oauth2-proxy starts with placeholder creds, 2) service-registry provisions real OIDC clients, 3) proxy gets restarted with real creds","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-21T22:38:47.981881-06:00","updated_at":"2025-12-30T07:15:14.534303779Z","closed_at":"2025-12-30T07:15:14.534303779Z","close_reason":"Folding into fort-0pb - the SSO skill will cover the provisioning flow as part of OIDC mode guidance."}
{"id":"fort-xzk","title":"Create pkgs/claude-code derivation for @anthropic-ai/claude-code","description":"Replace runtime npm install with proper Nix derivation using buildNpmPackage or similar","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T21:23:27.212414-06:00","updated_at":"2025-12-21T21:34:24.368933-06:00","closed_at":"2025-12-21T21:34:24.368933-06:00","close_reason":"Closed"}
{"id":"fort-z0b","title":"Investigate lldap-bootstrap flakiness","description":"lldap-bootstrap.service occasionally fails with 'jq: parse error: Invalid numeric literal at line 1, column 5'. Observed during deploy to drhorrible. May be a race condition or malformed secret file.","status":"open","priority":4,"issue_type":"bug","created_at":"2025-12-21T12:46:06.509684-06:00","updated_at":"2025-12-21T12:46:06.509684-06:00"}
{"id":"fort-zk9","title":"Create apps/claude-code-ui app module","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-21T21:14:09.693182-06:00","updated_at":"2025-12-21T22:17:42.711976-06:00","closed_at":"2025-12-21T22:17:42.711976-06:00","close_reason":"App module written with OAuth support","dependencies":[{"issue_id":"fort-zk9","depends_on_id":"fort-244","type":"blocks","created_at":"2025-12-21T21:14:15.207987-06:00","created_by":"daemon"},{"issue_id":"fort-zk9","depends_on_id":"fort-xzk","type":"blocks","created_at":"2025-12-21T21:23:44.154292-06:00","created_by":"daemon"},{"issue_id":"fort-zk9","depends_on_id":"fort-69s","type":"blocks","created_at":"2025-12-21T21:23:44.392207-06:00","created_by":"daemon"}]}
